{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем корпус текстов из файла train.json. Заглянем в набор данных с помощью data.head(10), чтобы представлять, как выглядит данный корпус текстов. Разобьем исходный набор данных на тренировочную и тестовую выборку в соотношении 70/30. В X будут содержаться наши тексты, представленные как вектор из частотностей слов. А в У - оценки тональности, но каждой из них мы назначим числовое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#загружаем дата-сет\n",
    "data = pd.read_json('train.json', encoding = 'utf-8')\n",
    "data.head(10)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#присваиваем классам числовое значение\n",
    "y = {'negative': -1, 'neutral': 0, 'positive': 1} \n",
    "data['y'] = data['sentiment'].map(lambda x: y[x])\n",
    "\n",
    "#делим данные на x и y, в x будут тексты, а в у - класс\n",
    "data_Y = data['y'].values\n",
    "data_X = data['text'].values\n",
    "\n",
    "#делим данные на тренировочную и тестовую выборку, тестовая выборка - 30% (здесь взята только часть примеров, а не весь корпус - это связано с мощностью компьютера)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = train_test_split(data_Y, data_X, test_size=0.3, shuffle=True)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = dataY_train[:700], dataY_test[:300], dataX_train[:700], dataX_test[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим “baseline” (отправную точку) - достаточно простую модель, используя сравнительно несложную схему репрезентации текста. Будем представлять наши тексты как вектор, включающий в себя частотности уникальных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "#для нашей тренировочной выборки создаем словарь частотностей всех уникальных словоформ \n",
    "vectorizer = CountVectorizer(min_df = 0, lowercase = True) \n",
    "vectorizer.fit(dataX_train)\n",
    "\n",
    "#преобразуем полученные данные в вектор\n",
    "X_train = vectorizer.transform(dataX_train).toarray()\n",
    "\n",
    "test_vectorizer = CountVectorizer(min_df = 0, lowercase = True, vocabulary=vectorizer.vocabulary_) \n",
    "test_vectorizer.fit(dataX_test)\n",
    "\n",
    "#представляем в виде вектора каждый текст из тестовой выборки, элементу с каким-либо индексом соответствует частотность слова, которое под этим же индексом находится в нашем словаре, в данном тексте\n",
    "X_test = test_vectorizer.transform(dataX_test).toarray()\n",
    "\n",
    "print(X_train[:10])\n",
    "print(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи 3-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно использовать как минимум три классификатора. Как минимум два из них будут иметь возможность возвращать важность атрибутов. Как минимум один будет иметь возможность получать вероятности классов. Нужно решить задачу классификации, рассмотрев сначала как задачу многоклассовой классификации (позитив/негатив/нейтральный класс). \n",
    "\n",
    "Сначала попробуем решить задачу многоклассовой классификации. Применим RandomDorest, ExtraTrees и линейный SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5933333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "linsvc_clf = LinearSVC(C=5, loss=\"hinge\", penalty = 'l2', multi_class = 'ovr')\n",
    "\n",
    "#применим gridsearch для поиска оптимальных значений гиперпараметров\n",
    "param_grid = {'C': list(range(1, 5)), 'loss': ['hinge', 'squared_hinge']}\n",
    "grid_search_cv = GridSearchCV(LinearSVC(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred1 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred1)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.17298522 0.50196701 0.32504777]\n",
      " [0.17233262 0.50008278 0.3275846 ]\n",
      " [0.17621644 0.51208972 0.31169384]\n",
      " [0.17429831 0.50801258 0.31768911]\n",
      " [0.17156481 0.50379776 0.32463742]\n",
      " [0.16432562 0.50282169 0.33285269]\n",
      " [0.17226095 0.51484634 0.31289272]\n",
      " [0.17243226 0.49847757 0.32909017]\n",
      " [0.1864296  0.50104514 0.31252526]\n",
      " [0.17628262 0.50133168 0.3223857 ]\n",
      " [0.17291714 0.50819463 0.31888823]\n",
      " [0.17879156 0.51788878 0.30331966]\n",
      " [0.18425416 0.50657659 0.30916926]\n",
      " [0.17454964 0.5118657  0.31358466]\n",
      " [0.18936213 0.50708793 0.30354994]\n",
      " [0.1707189  0.50830341 0.3209777 ]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.17731089 0.50203321 0.3206559 ]\n",
      " [0.16592766 0.49905335 0.33501899]\n",
      " [0.17456252 0.51473349 0.31070399]\n",
      " [0.16326924 0.48635796 0.3503728 ]\n",
      " [0.17086808 0.51105605 0.31807586]\n",
      " [0.17568118 0.50256915 0.32174968]\n",
      " [0.17360885 0.51089764 0.31549351]\n",
      " [0.17828921 0.5246732  0.29703759]\n",
      " [0.17780191 0.50407222 0.31812588]\n",
      " [0.16496468 0.50610973 0.32892559]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17059947 0.49447951 0.33492102]\n",
      " [0.17185221 0.51156634 0.31658145]\n",
      " [0.17010056 0.50155406 0.32834538]\n",
      " [0.18200962 0.49261285 0.32537754]\n",
      " [0.16575477 0.51877326 0.31547197]\n",
      " [0.17179207 0.50419579 0.32401214]\n",
      " [0.17312955 0.51196494 0.3149055 ]\n",
      " [0.17146989 0.50940009 0.31913003]\n",
      " [0.17375814 0.51495176 0.3112901 ]\n",
      " [0.17489199 0.50816343 0.31694457]\n",
      " [0.18064444 0.49843185 0.32092371]\n",
      " [0.17316212 0.52001216 0.30682572]\n",
      " [0.17321684 0.51219934 0.31458382]\n",
      " [0.1992155  0.50957987 0.29120464]\n",
      " [0.17091535 0.51094796 0.31813669]\n",
      " [0.17290897 0.50824992 0.31884111]\n",
      " [0.1733638  0.50141554 0.32522066]\n",
      " [0.17248131 0.50566896 0.32184973]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17621098 0.51273938 0.31104964]\n",
      " [0.17482958 0.50021837 0.32495205]\n",
      " [0.1781052  0.50972166 0.31217314]\n",
      " [0.17484417 0.49758204 0.32757379]\n",
      " [0.17335992 0.51218757 0.3144525 ]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17266878 0.50659823 0.32073299]\n",
      " [0.17348498 0.51083549 0.31567953]\n",
      " [0.17492407 0.50968533 0.31539061]\n",
      " [0.18263513 0.50261804 0.31474682]\n",
      " [0.17783772 0.50376771 0.31839457]\n",
      " [0.16703472 0.51499682 0.31796847]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.16396104 0.49539176 0.3406472 ]\n",
      " [0.17380692 0.51544078 0.3107523 ]\n",
      " [0.17601475 0.50866584 0.31531941]\n",
      " [0.1805998  0.51143513 0.30796507]\n",
      " [0.16506875 0.50902565 0.3259056 ]\n",
      " [0.17717192 0.51381006 0.30901801]\n",
      " [0.17366949 0.50884876 0.31748176]\n",
      " [0.17544558 0.50902322 0.31553121]\n",
      " [0.17470268 0.51979559 0.30550172]\n",
      " [0.17445226 0.5064006  0.31914714]\n",
      " [0.17772947 0.51247285 0.30979768]\n",
      " [0.17021575 0.51495747 0.31482678]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17800696 0.50840442 0.31358862]\n",
      " [0.17671132 0.51924643 0.30404225]\n",
      " [0.20677749 0.49529863 0.29792388]\n",
      " [0.17173139 0.51751038 0.31075823]\n",
      " [0.16582872 0.50670318 0.3274681 ]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.16838424 0.50663387 0.32498188]\n",
      " [0.16787146 0.49863885 0.33348969]\n",
      " [0.17662913 0.50523023 0.31814064]\n",
      " [0.17556671 0.50456599 0.3198673 ]\n",
      " [0.20498373 0.5017248  0.29329147]\n",
      " [0.1753185  0.50941407 0.31526743]\n",
      " [0.18171116 0.50984368 0.30844516]\n",
      " [0.16455235 0.50051055 0.3349371 ]\n",
      " [0.17254271 0.510375   0.31708229]\n",
      " [0.17015011 0.51866321 0.31118668]\n",
      " [0.17004437 0.49007107 0.33988456]\n",
      " [0.17591048 0.50171729 0.32237222]\n",
      " [0.17505175 0.50015583 0.32479242]\n",
      " [0.17738101 0.51409541 0.30852359]\n",
      " [0.16892173 0.50099718 0.33008109]\n",
      " [0.1673198  0.49715721 0.33552299]\n",
      " [0.17029985 0.50622213 0.32347802]\n",
      " [0.17360885 0.51089764 0.31549351]\n",
      " [0.1671679  0.5116793  0.3211528 ]\n",
      " [0.18632255 0.50404978 0.30962767]\n",
      " [0.17205389 0.50626994 0.32167617]\n",
      " [0.17798582 0.50475605 0.31725812]\n",
      " [0.17298387 0.50331097 0.32370517]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.16254332 0.49483984 0.34261684]\n",
      " [0.18730006 0.49966417 0.31303577]\n",
      " [0.16690088 0.50361787 0.32948126]\n",
      " [0.17346591 0.50247775 0.32405633]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.18343309 0.52961849 0.28694842]\n",
      " [0.16980322 0.51386909 0.31632769]\n",
      " [0.18268863 0.50806518 0.30924618]\n",
      " [0.17391349 0.49702358 0.32906293]\n",
      " [0.17694967 0.51837075 0.30467958]\n",
      " [0.16869844 0.50553001 0.32577154]\n",
      " [0.17464442 0.49832576 0.32702982]\n",
      " [0.18904842 0.50982612 0.30112546]\n",
      " [0.16431352 0.50222744 0.33345904]\n",
      " [0.17900166 0.51295963 0.30803871]\n",
      " [0.1724217  0.49808185 0.32949645]\n",
      " [0.17092473 0.50886769 0.32020758]\n",
      " [0.1673959  0.503679   0.32892509]\n",
      " [0.16264954 0.48768121 0.34966925]\n",
      " [0.17298423 0.51639493 0.31062084]\n",
      " [0.17169471 0.48219953 0.34610576]\n",
      " [0.18091176 0.51036057 0.30872767]\n",
      " [0.17916943 0.49053507 0.3302955 ]\n",
      " [0.17696977 0.51014513 0.3128851 ]\n",
      " [0.16649098 0.51476812 0.3187409 ]\n",
      " [0.17685938 0.50785832 0.3152823 ]\n",
      " [0.17418507 0.51058387 0.31523106]\n",
      " [0.17342356 0.48997852 0.33659791]\n",
      " [0.18145646 0.50424046 0.31430309]\n",
      " [0.17290897 0.50824992 0.31884111]\n",
      " [0.18343259 0.50692531 0.3096421 ]\n",
      " [0.18103015 0.50779233 0.31117752]\n",
      " [0.17364259 0.50403337 0.32232404]\n",
      " [0.14947087 0.54910779 0.30142133]\n",
      " [0.17902899 0.52137233 0.29959868]\n",
      " [0.16679928 0.50944121 0.32375951]\n",
      " [0.17562353 0.53940745 0.28496902]\n",
      " [0.1721794  0.50856125 0.31925935]\n",
      " [0.1662877  0.51848368 0.31522862]\n",
      " [0.1717446  0.50161921 0.32663619]\n",
      " [0.19047851 0.49871171 0.31080978]\n",
      " [0.17735688 0.51648614 0.30615698]\n",
      " [0.1677743  0.50588962 0.32633608]\n",
      " [0.16629064 0.49919595 0.33451341]\n",
      " [0.17039311 0.50535437 0.32425252]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.17378713 0.49444445 0.33176842]\n",
      " [0.16960921 0.50019931 0.33019149]\n",
      " [0.18268365 0.50521471 0.31210164]\n",
      " [0.1884211  0.50933085 0.30224804]\n",
      " [0.17957084 0.50982539 0.31060378]\n",
      " [0.17029114 0.49785624 0.33185262]\n",
      " [0.17193197 0.50992719 0.31814084]\n",
      " [0.17666324 0.50182175 0.32151502]\n",
      " [0.16995849 0.51095634 0.31908517]\n",
      " [0.1739924  0.5210909  0.3049167 ]\n",
      " [0.18357855 0.50504367 0.31137778]\n",
      " [0.17448119 0.50911546 0.31640335]\n",
      " [0.16823806 0.50446315 0.32729879]\n",
      " [0.17297259 0.51910287 0.30792454]\n",
      " [0.16990638 0.49980684 0.33028678]\n",
      " [0.1613995  0.49672968 0.34187082]\n",
      " [0.16742166 0.51494128 0.31763705]\n",
      " [0.17093814 0.52174805 0.3073138 ]\n",
      " [0.1819677  0.51753713 0.30049517]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.18556123 0.5209919  0.29344687]\n",
      " [0.17148858 0.50188357 0.32662785]\n",
      " [0.17873732 0.50736825 0.31389443]\n",
      " [0.16662432 0.50427066 0.32910502]\n",
      " [0.17473004 0.49940323 0.32586673]\n",
      " [0.17603605 0.50957304 0.31439091]\n",
      " [0.16843303 0.51355652 0.31801045]\n",
      " [0.1831035  0.50257303 0.31432347]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.1705466  0.52514936 0.30430404]\n",
      " [0.17092558 0.49890241 0.33017201]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.17257354 0.52601584 0.30141062]\n",
      " [0.17204089 0.50643912 0.32151998]\n",
      " [0.17484417 0.49758204 0.32757379]\n",
      " [0.17199547 0.50677681 0.32122772]\n",
      " [0.17261515 0.50628877 0.32109607]\n",
      " [0.17563318 0.51403308 0.31033374]\n",
      " [0.17221143 0.51323128 0.31455729]\n",
      " [0.17667609 0.5024606  0.3208633 ]\n",
      " [0.18532056 0.51036302 0.30431642]\n",
      " [0.18201245 0.51131861 0.30666894]\n",
      " [0.19049612 0.51184104 0.29766284]\n",
      " [0.17424403 0.50582739 0.31992858]\n",
      " [0.17672869 0.50539641 0.3178749 ]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.17201328 0.51066667 0.31732005]\n",
      " [0.17553539 0.51957169 0.30489292]\n",
      " [0.16968434 0.50474094 0.32557472]\n",
      " [0.17051875 0.50623417 0.32324708]\n",
      " [0.1783102  0.51256227 0.30912754]\n",
      " [0.17333282 0.52238919 0.30427798]\n",
      " [0.1813488  0.50720874 0.31144246]\n",
      " [0.17878591 0.51718744 0.30402665]\n",
      " [0.16981598 0.50565524 0.32452878]\n",
      " [0.191941   0.50511075 0.30294825]\n",
      " [0.16578683 0.49158301 0.34263016]\n",
      " [0.19304414 0.50956327 0.29739258]\n",
      " [0.1773451  0.5099643  0.3126906 ]\n",
      " [0.16990736 0.50535434 0.3247383 ]\n",
      " [0.19417736 0.50177197 0.30405067]\n",
      " [0.17596245 0.51487286 0.30916469]\n",
      " [0.17474454 0.51122489 0.31403057]\n",
      " [0.17104918 0.51053416 0.31841666]\n",
      " [0.17183445 0.51068192 0.31748363]\n",
      " [0.16861285 0.50789104 0.3234961 ]\n",
      " [0.16806793 0.50249353 0.32943854]\n",
      " [0.17284584 0.50634472 0.32080943]\n",
      " [0.18808343 0.51481132 0.29710524]\n",
      " [0.17509282 0.51086007 0.31404711]\n",
      " [0.19033543 0.50642492 0.30323964]\n",
      " [0.16999649 0.50889808 0.32110542]\n",
      " [0.19828701 0.51737919 0.2843338 ]\n",
      " [0.12673338 0.44517486 0.42809176]\n",
      " [0.1777757  0.52668382 0.29554048]\n",
      " [0.17168472 0.50115853 0.32715676]\n",
      " [0.16950173 0.50064778 0.32985049]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.18850892 0.51122975 0.30026133]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17375814 0.51495176 0.3112901 ]\n",
      " [0.1912961  0.49729895 0.31140495]\n",
      " [0.16911795 0.52007857 0.31080348]\n",
      " [0.16822987 0.52045842 0.31131171]\n",
      " [0.174251   0.50597331 0.31977569]\n",
      " [0.16590192 0.50672705 0.32737103]\n",
      " [0.17019303 0.509288   0.32051897]\n",
      " [0.17390641 0.50780481 0.31828878]\n",
      " [0.17581826 0.5026727  0.32150905]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17242775 0.51298932 0.31458294]\n",
      " [0.16889943 0.52093923 0.31016134]\n",
      " [0.17261515 0.50628877 0.32109607]\n",
      " [0.17194431 0.50661726 0.32143842]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17151491 0.51211281 0.31637228]\n",
      " [0.17628262 0.50133168 0.3223857 ]\n",
      " [0.17099053 0.50789012 0.32111935]\n",
      " [0.17159826 0.51365544 0.3147463 ]\n",
      " [0.17106689 0.51159386 0.31733925]\n",
      " [0.17366138 0.50467221 0.32166641]\n",
      " [0.15764263 0.48710717 0.35525021]\n",
      " [0.21145629 0.50066009 0.28788362]\n",
      " [0.17226095 0.51484634 0.31289272]\n",
      " [0.17452559 0.50719499 0.31827943]\n",
      " [0.18141842 0.51062423 0.30795735]\n",
      " [0.17552438 0.49705986 0.32741576]\n",
      " [0.17425109 0.50192485 0.32382406]\n",
      " [0.17393442 0.51302246 0.31304311]\n",
      " [0.18120743 0.50136666 0.31742592]\n",
      " [0.17965895 0.51403237 0.30630868]\n",
      " [0.17748066 0.51006489 0.31245445]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.17488218 0.50639023 0.3187276 ]\n",
      " [0.17007521 0.50487786 0.32504693]\n",
      " [0.17660407 0.50973094 0.31366499]\n",
      " [0.17306781 0.50018723 0.32674496]\n",
      " [0.17346591 0.50247775 0.32405633]\n",
      " [0.17263186 0.51023051 0.31713763]\n",
      " [0.17377825 0.51026742 0.31595433]\n",
      " [0.17662913 0.50523023 0.31814064]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.16958183 0.50916304 0.32125513]\n",
      " [0.1737221  0.51115048 0.31512742]\n",
      " [0.17022036 0.51655156 0.31322807]\n",
      " [0.17422678 0.50792933 0.31784389]\n",
      " [0.15492497 0.51192841 0.33314662]\n",
      " [0.16148322 0.5217016  0.31681518]\n",
      " [0.17759775 0.50539027 0.31701199]\n",
      " [0.20813954 0.49457454 0.29728592]\n",
      " [0.17655443 0.51177778 0.31166779]\n",
      " [0.17172622 0.5140714  0.31420239]\n",
      " [0.17485277 0.50783542 0.31731181]\n",
      " [0.17380331 0.51480448 0.31139221]\n",
      " [0.16894434 0.50958617 0.32146948]\n",
      " [0.17531806 0.51707472 0.30760723]\n",
      " [0.17648048 0.51024449 0.31327503]\n",
      " [0.17285961 0.50832016 0.31882023]\n",
      " [0.17505175 0.51015583 0.31479242]\n",
      " [0.17521734 0.50911725 0.31566541]\n",
      " [0.17155221 0.50301022 0.32543757]\n",
      " [0.16455235 0.50051055 0.3349371 ]\n",
      " [0.17430617 0.51231089 0.31338294]\n",
      " [0.17255584 0.50360323 0.32384092]\n",
      " [0.17341369 0.50898558 0.31760073]\n",
      " [0.17245867 0.51812735 0.30941398]\n",
      " [0.17460828 0.51210842 0.3132833 ]\n",
      " [0.17045801 0.51674778 0.3127942 ]\n",
      " [0.1718163  0.51514912 0.31303458]\n",
      " [0.20509069 0.51624046 0.27866885]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['00', '04', '05', ..., 'қтж', 'құрмет', 'үшін'], dtype='<U66')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "rnd_clf.fit(X_train, dataY_train)\n",
    "\n",
    "#создадим конвейер для векторайзера и классификатора\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred2 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred2)\n",
    "\n",
    "#выводим метрики качества, accuracy, важность каждого слова, вероятности классов и список слов, на которые больше всего опираетсямодель при выборе класса\n",
    "print(accuracy_score(dataY_test, y_pred2))\n",
    "print(rnd_clf.feature_importances_)\n",
    "print(rnd_clf.predict_proba(X_test))\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['RandomForestClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47333333333333333\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.17289671 0.50849552 0.31860777]\n",
      " [0.16941997 0.50112626 0.32945377]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17391328 0.50860444 0.31748228]\n",
      " [0.17497727 0.50942147 0.31560126]\n",
      " [0.16736544 0.49921916 0.33341539]\n",
      " [0.17227958 0.51344132 0.3142791 ]\n",
      " [0.18790904 0.48459826 0.32749269]\n",
      " [0.17668274 0.50861052 0.31470674]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1824514  0.50648947 0.31105913]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.18590026 0.50631844 0.3077813 ]\n",
      " [0.16874923 0.49897915 0.33227162]\n",
      " [0.17426476 0.50161226 0.32412298]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17228227 0.50693404 0.32078369]\n",
      " [0.18061653 0.5021319  0.31725158]\n",
      " [0.16414041 0.49459419 0.3412654 ]\n",
      " [0.17282769 0.51043099 0.31674132]\n",
      " [0.182613   0.4989562  0.3184308 ]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17322197 0.50575603 0.321022  ]\n",
      " [0.17149126 0.503495   0.32501374]\n",
      " [0.17227419 0.50784927 0.31987654]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17620964 0.50534479 0.31844558]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17052915 0.50540775 0.3240631 ]\n",
      " [0.18585134 0.50418589 0.30996277]\n",
      " [0.16554093 0.51483141 0.31962766]\n",
      " [0.18134616 0.51001652 0.30863732]\n",
      " [0.17132151 0.50601394 0.32266455]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17948113 0.50805745 0.31246142]\n",
      " [0.18837026 0.50679567 0.30483406]\n",
      " [0.17237623 0.50827376 0.31935001]\n",
      " [0.174968   0.51086426 0.31416774]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.18203383 0.50592458 0.31204159]\n",
      " [0.17060664 0.50013891 0.32925446]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16759644 0.49910025 0.33330332]\n",
      " [0.1823974  0.50379069 0.31381191]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16955653 0.49604303 0.33440045]\n",
      " [0.17718087 0.5104088  0.31241033]\n",
      " [0.16736544 0.49921916 0.33341539]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17331718 0.50178238 0.32490045]\n",
      " [0.174968   0.51086426 0.31416774]\n",
      " [0.17237623 0.50827376 0.31935001]\n",
      " [0.172701   0.50965386 0.31764514]\n",
      " [0.18235724 0.50384445 0.31379831]\n",
      " [0.17762514 0.50053946 0.3218354 ]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.18264763 0.50854118 0.30881118]\n",
      " [0.16763476 0.49449903 0.33786621]\n",
      " [0.1749913  0.51524103 0.30976766]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1756479  0.51330762 0.31104447]\n",
      " [0.17738801 0.50899476 0.31361723]\n",
      " [0.17236228 0.50385919 0.32377853]\n",
      " [0.18825205 0.49922078 0.31252717]\n",
      " [0.1801849  0.50616012 0.31365497]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17489083 0.50901248 0.31609669]\n",
      " [0.16827278 0.5024558  0.32927141]\n",
      " [0.20594011 0.49657813 0.29748176]\n",
      " [0.17237623 0.50827376 0.31935001]\n",
      " [0.17184199 0.5062357  0.3219223 ]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1716412  0.49349515 0.33486365]\n",
      " [0.1736308  0.51186952 0.31449968]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.19768185 0.49911823 0.30319992]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16989174 0.51498666 0.3151216 ]\n",
      " [0.17209398 0.51086713 0.31703889]\n",
      " [0.17247187 0.5026378  0.32489033]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.20413936 0.50786771 0.28799293]\n",
      " [0.1699425  0.50218172 0.32787578]\n",
      " [0.17344221 0.50930632 0.31725146]\n",
      " [0.17289671 0.50849552 0.31860777]\n",
      " [0.18237866 0.50382218 0.31379917]\n",
      " [0.16747721 0.50119027 0.33133252]\n",
      " [0.16978395 0.51198425 0.3182318 ]\n",
      " [0.20257849 0.50383808 0.29358343]\n",
      " [0.17555795 0.50482775 0.3196143 ]\n",
      " [0.1807045  0.50300147 0.31629402]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16200079 0.49068815 0.34731107]\n",
      " [0.17779445 0.50602945 0.3161761 ]\n",
      " [0.16848003 0.50364681 0.32787316]\n",
      " [0.17056786 0.49873623 0.33069592]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17637305 0.50989398 0.31373297]\n",
      " [0.17227825 0.5043822  0.32333955]\n",
      " [0.18498074 0.50447111 0.31054815]\n",
      " [0.16811765 0.49926656 0.33261579]\n",
      " [0.17322197 0.50575603 0.321022  ]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17090301 0.51011989 0.31897709]\n",
      " [0.17234452 0.51293822 0.31471726]\n",
      " [0.17419588 0.51328609 0.31251803]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17668274 0.50861052 0.31470674]\n",
      " [0.17228227 0.50693404 0.32078369]\n",
      " [0.18251384 0.48446381 0.33302235]\n",
      " [0.17539162 0.47954082 0.34506756]\n",
      " [0.17201828 0.51957468 0.30840704]\n",
      " [0.16399062 0.49954186 0.33646751]\n",
      " [0.17764891 0.51030777 0.31204332]\n",
      " [0.17428209 0.50441396 0.32130395]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16500787 0.52332808 0.31166405]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17225155 0.51505538 0.31269308]\n",
      " [0.16736544 0.49921916 0.33341539]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17428209 0.50441396 0.32130395]\n",
      " [0.174968   0.51086426 0.31416774]\n",
      " [0.18395741 0.50797553 0.30806706]\n",
      " [0.17176163 0.50951433 0.31872403]\n",
      " [0.16157967 0.5413823  0.29703803]\n",
      " [0.17521889 0.51380017 0.31098094]\n",
      " [0.1824126  0.50386599 0.31372141]\n",
      " [0.1972977  0.49602674 0.30667556]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17229558 0.50385057 0.32385385]\n",
      " [0.20013488 0.49423269 0.30563243]\n",
      " [0.1783957  0.51335318 0.30825112]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1638324  0.49992393 0.33624367]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16736544 0.49921916 0.33341539]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17817226 0.51092893 0.31089881]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17289671 0.50849552 0.31860777]\n",
      " [0.17230492 0.50604319 0.3216519 ]\n",
      " [0.17305108 0.50670024 0.32024868]\n",
      " [0.17831933 0.50541505 0.31626562]\n",
      " [0.17305108 0.50670024 0.32024868]\n",
      " [0.17233916 0.51742883 0.31023201]\n",
      " [0.18085606 0.50697993 0.31216401]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17099698 0.51145961 0.31754341]\n",
      " [0.17192012 0.50670317 0.32137671]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16640053 0.49658758 0.33701189]\n",
      " [0.17357907 0.51119725 0.31522368]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.19884479 0.49362674 0.30752848]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17179919 0.51075874 0.31744207]\n",
      " [0.16736544 0.49921916 0.33341539]\n",
      " [0.17895896 0.51317329 0.30786776]\n",
      " [0.1726667  0.50720883 0.32012447]\n",
      " [0.17057295 0.50201602 0.32741103]\n",
      " [0.174968   0.51086426 0.31416774]\n",
      " [0.17055133 0.50074789 0.32870078]\n",
      " [0.19701168 0.49561993 0.30736839]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1735515  0.51276879 0.31367971]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17606399 0.51522747 0.30870854]\n",
      " [0.17426476 0.50161226 0.32412298]\n",
      " [0.17264433 0.50597207 0.3213836 ]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16665609 0.50988614 0.32345777]\n",
      " [0.17319022 0.50585685 0.32095293]\n",
      " [0.17289671 0.50849552 0.31860777]\n",
      " [0.17538166 0.50937385 0.31524449]\n",
      " [0.1741291  0.51333683 0.31253407]\n",
      " [0.17999386 0.50507573 0.31493042]\n",
      " [0.16944844 0.51445559 0.31609596]\n",
      " [0.16923199 0.48893507 0.34183294]\n",
      " [0.18524662 0.49812068 0.31663269]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.174968   0.51086426 0.31416774]\n",
      " [0.17275053 0.51821055 0.30903892]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17137522 0.50068906 0.32793572]\n",
      " [0.17326875 0.5150234  0.31170784]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17637305 0.50989398 0.31373297]\n",
      " [0.16863193 0.51023247 0.3211356 ]\n",
      " [0.18135523 0.50631885 0.31232592]\n",
      " [0.1638324  0.49179893 0.34436867]\n",
      " [0.1979686  0.49796265 0.30406875]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17300056 0.51248711 0.31451234]\n",
      " [0.17742985 0.51287477 0.30969538]\n",
      " [0.17365209 0.50868755 0.31766036]\n",
      " [0.17113029 0.50671936 0.32215035]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17237623 0.50827376 0.31935001]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17067698 0.51243291 0.31689011]\n",
      " [0.17236348 0.50380632 0.32383019]\n",
      " [0.17988346 0.50811767 0.31199888]\n",
      " [0.1723113  0.50635152 0.32133719]\n",
      " [0.16860621 0.50484324 0.32655056]\n",
      " [0.17060039 0.50313548 0.32626413]\n",
      " [0.19788788 0.50236898 0.29974313]\n",
      " [0.15490489 0.43985476 0.40524035]\n",
      " [0.17594403 0.51038653 0.31366944]\n",
      " [0.16557932 0.5012396  0.33318108]\n",
      " [0.1781302  0.50316553 0.31870427]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.18659746 0.50213533 0.31126721]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17948113 0.50805745 0.31246142]\n",
      " [0.19701168 0.49561993 0.30736839]\n",
      " [0.17233916 0.51742883 0.31023201]\n",
      " [0.17289671 0.50849552 0.31860777]\n",
      " [0.173206   0.50124127 0.32555274]\n",
      " [0.17235217 0.51393107 0.31371676]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17228227 0.50693404 0.32078369]\n",
      " [0.17068931 0.49423877 0.33507193]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17056982 0.50794383 0.32148635]\n",
      " [0.16665609 0.50988614 0.32345777]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17230492 0.50604319 0.3216519 ]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17252959 0.50412008 0.32335032]\n",
      " [0.17052144 0.4986746  0.33080396]\n",
      " [0.17258139 0.50339384 0.32402477]\n",
      " [0.18384356 0.50581147 0.31034497]\n",
      " [0.17227958 0.51344132 0.3142791 ]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1735515  0.51276879 0.31367971]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16822765 0.50112336 0.33064899]\n",
      " [0.17230755 0.50382848 0.32386397]\n",
      " [0.19006951 0.50263653 0.30729396]\n",
      " [0.19585724 0.49827953 0.30586323]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.18924892 0.48884976 0.32190132]\n",
      " [0.16998628 0.50102206 0.32899165]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16736544 0.49921916 0.33341539]\n",
      " [0.17056786 0.49873623 0.33069592]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17230347 0.51391645 0.31378008]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.16873294 0.50086743 0.33039963]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17110481 0.50337991 0.32551528]\n",
      " [0.17224839 0.48992929 0.33782232]\n",
      " [0.16690312 0.52932042 0.30377645]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.18842147 0.50432828 0.30725025]\n",
      " [0.17538166 0.50937385 0.31524449]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.1710705  0.51297678 0.31595272]\n",
      " [0.17233916 0.51742883 0.31023201]\n",
      " [0.17232834 0.50384445 0.32382721]\n",
      " [0.17217415 0.51356096 0.31426489]\n",
      " [0.17314088 0.50632848 0.32053064]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17231586 0.51305206 0.31463209]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17237623 0.50827376 0.31935001]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17230347 0.51391645 0.31378008]\n",
      " [0.1736308  0.51186952 0.31449968]\n",
      " [0.1741058  0.50896006 0.31693415]\n",
      " [0.17061238 0.51235009 0.31703753]\n",
      " [0.17227958 0.51344132 0.3142791 ]\n",
      " [0.17233916 0.51742883 0.31023201]\n",
      " [0.1723113  0.50635152 0.32133719]\n",
      " [0.17859868 0.51835846 0.30304286]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['01', '026', '04', ..., 'қазақстан', 'үшін', 'ұлы'], dtype='<U66')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ext_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "ext_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(ExtraTreesClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred3 = grid_search_cv.predict(X_test)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred3))\n",
    "print(ext_clf.feature_importances_)\n",
    "print(ext_clf.predict_proba(X_test))\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['ExtraTreesClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока лучший результат показывает линейный SVM (accuracy = 0.59).\n",
    "\n",
    "Затем попробуем решить задачу бинарной классификации. Для этого сначала нужно присвоить другие значения оценкам тональности, чтобы их было всего два: 1 и -1. Здесь применим классификаторы RandomForest, ExtraTrees и логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зададим новые численные значения для классов\n",
    "y = {'negative': -1, 'neutral': 1, 'positive': 1} \n",
    "data['y'] = data['sentiment'].map(lambda x: y[x])\n",
    "\n",
    "data_Y = data['y'].values\n",
    "data_X = data['text'].values\n",
    "\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = train_test_split(data_Y, data_X, test_size=0.3)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = dataY_train[:700], dataY_test[:300], dataX_train[:700], dataX_test[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.16982263 0.83017737]\n",
      " [0.17840654 0.82159346]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1740095  0.8259905 ]\n",
      " [0.176361   0.823639  ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17113738 0.82886262]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16849734 0.83150266]\n",
      " [0.17155645 0.82844355]\n",
      " [0.16310269 0.83689731]\n",
      " [0.19066833 0.80933167]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16533161 0.83466839]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17161425 0.82838575]\n",
      " [0.16646324 0.83353676]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17693027 0.82306973]\n",
      " [0.17815876 0.82184124]\n",
      " [0.16722502 0.83277498]\n",
      " [0.17132267 0.82867733]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17155645 0.82844355]\n",
      " [0.17168651 0.82831349]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17146241 0.82853759]\n",
      " [0.16836419 0.83163581]\n",
      " [0.17143179 0.82856821]\n",
      " [0.18485992 0.81514008]\n",
      " [0.16995884 0.83004116]\n",
      " [0.19264592 0.80735408]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18388843 0.81611157]\n",
      " [0.16955907 0.83044093]\n",
      " [0.1714553  0.8285447 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18039607 0.81960393]\n",
      " [0.16784898 0.83215102]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17306361 0.82693639]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17147242 0.82852758]\n",
      " [0.20467499 0.79532501]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16979265 0.83020735]\n",
      " [0.17808526 0.82191474]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18399511 0.81600489]\n",
      " [0.18471585 0.81528415]\n",
      " [0.16849734 0.83150266]\n",
      " [0.17129061 0.82870939]\n",
      " [0.16849734 0.83150266]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17133627 0.82866373]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16578371 0.83421629]\n",
      " [0.1813209  0.8186791 ]\n",
      " [0.16159364 0.83840636]\n",
      " [0.17038808 0.82961192]\n",
      " [0.17745137 0.82254863]\n",
      " [0.17133627 0.82866373]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16943284 0.83056716]\n",
      " [0.19161744 0.80838256]\n",
      " [0.16800393 0.83199607]\n",
      " [0.17104439 0.82895561]\n",
      " [0.16808807 0.83191193]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16849734 0.83150266]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16722502 0.83277498]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17147242 0.82852758]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17502226 0.82497774]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16303321 0.83696679]\n",
      " [0.17086734 0.82913266]\n",
      " [0.17158666 0.82841334]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17977232 0.82022768]\n",
      " [0.17168651 0.82831349]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18134539 0.81865461]\n",
      " [0.16820732 0.83179268]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16914425 0.83085575]\n",
      " [0.16644331 0.83355669]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17150849 0.82849151]\n",
      " [0.19066833 0.80933167]\n",
      " [0.26577052 0.73422948]\n",
      " [0.1705213  0.8294787 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16578371 0.83421629]\n",
      " [0.16808807 0.83191193]\n",
      " [0.16495419 0.83504581]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17737247 0.82262753]\n",
      " [0.16159364 0.83840636]\n",
      " [0.17396046 0.82603954]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16825418 0.83174582]\n",
      " [0.17832652 0.82167348]\n",
      " [0.1740754  0.8259246 ]\n",
      " [0.17176264 0.82823736]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16748235 0.83251765]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16427466 0.83572534]\n",
      " [0.17165342 0.82834658]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16689374 0.83310626]\n",
      " [0.19290335 0.80709665]\n",
      " [0.16820732 0.83179268]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16636961 0.83363039]\n",
      " [0.19849409 0.80150591]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.17124868 0.82875132]\n",
      " [0.16999498 0.83000502]\n",
      " [0.18381286 0.81618714]\n",
      " [0.16979265 0.83020735]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1714553  0.8285447 ]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17602628 0.82397372]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16943284 0.83056716]\n",
      " [0.17176264 0.82823736]\n",
      " [0.16533161 0.83466839]\n",
      " [0.16943284 0.83056716]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17735507 0.82264493]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17427492 0.82572508]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17414474 0.82585526]\n",
      " [0.21356293 0.78643707]\n",
      " [0.17133627 0.82866373]\n",
      " [0.17150849 0.82849151]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17959113 0.82040887]\n",
      " [0.17480801 0.82519199]\n",
      " [0.16533161 0.83466839]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17940524 0.82059476]\n",
      " [0.174918   0.825082  ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17155645 0.82844355]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16564975 0.83435025]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16784898 0.83215102]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17808526 0.82191474]\n",
      " [0.16824063 0.83175937]\n",
      " [0.17158666 0.82841334]\n",
      " [0.1697466  0.8302534 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17520556 0.82479444]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16903837 0.83096163]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.1760413  0.8239587 ]\n",
      " [0.16564975 0.83435025]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17464176 0.82535824]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17961517 0.82038483]\n",
      " [0.17153974 0.82846026]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18248538 0.81751462]\n",
      " [0.1791779  0.8208221 ]\n",
      " [0.17372213 0.82627787]\n",
      " [0.17146004 0.82853996]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1922179  0.8077821 ]\n",
      " [0.1714553  0.8285447 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16722502 0.83277498]\n",
      " [0.18503859 0.81496141]\n",
      " [0.19698439 0.80301561]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17492842 0.82507158]\n",
      " [0.23411858 0.76588142]\n",
      " [0.18172252 0.81827748]\n",
      " [0.16619853 0.83380147]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.19865434 0.80134566]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16382256 0.83617744]\n",
      " [0.1685607  0.8314393 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.19328425 0.80671575]\n",
      " [0.16636961 0.83363039]\n",
      " [0.16578371 0.83421629]\n",
      " [0.16999498 0.83000502]\n",
      " [0.17144862 0.82855138]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16808807 0.83191193]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16903837 0.83096163]\n",
      " [0.1756875  0.8243125 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18870578 0.81129422]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1745735  0.8254265 ]\n",
      " [0.17055909 0.82944091]\n",
      " [0.16310269 0.83689731]\n",
      " [0.22989713 0.77010287]\n",
      " [0.17131852 0.82868148]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18458058 0.81541942]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17155645 0.82844355]\n",
      " [0.17179664 0.82820336]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        37\n",
      "          1       0.88      0.99      0.93       263\n",
      "\n",
      "avg / total       0.77      0.87      0.81       300\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['00', '047', '10', '103', '11', '1126', '115', '12', '128', '13',\n",
       "       '1306', '14', '15', '16', '18', '19', '192', '20', '2007', '2009',\n",
       "       '2013', '2015', '2016', '2017', '208', '21', '23', '234', '25',\n",
       "       '250', '259', '27', '29', '300er', '318', '333', '36', '404',\n",
       "       '4187', '44', '45', '49', '500', '53', '54', '644', '659', '662',\n",
       "       '69', '727', '7373', '738', '758', '803', '84', '900', '95', '990',\n",
       "       'bank', 'banker', 'bloomberg', 'emitters', 'google', 'https',\n",
       "       'hyundai', 'inform', 'kalina', 'kapital', 'kapitala', 'kase',\n",
       "       'kaz', 'kazakhstan', 'kegoc', 'kz', 'kzbbb', 'lot', 'ministr',\n",
       "       'pavon', 'pdf', 'quot', 'raquo', 'renault', 'rezonans', 'shell',\n",
       "       'zonakz', 'абаиловского', 'аварийная', 'августа', 'автобизнеса',\n",
       "       'автобусы', 'автомобилей', 'автомобильной', 'авторизацию',\n",
       "       'агентов', 'агромашхолдинг', 'административной',\n",
       "       'администрирования', 'айтимбетов', 'акимата', 'акишева',\n",
       "       'актауский', 'актюбинской', 'алатаумунайалтын', 'алдабергеновича',\n",
       "       'александр', 'алимбетов', 'алименты', 'алмаз', 'алматинские',\n",
       "       'алматы', 'алтаевой', 'амортизацию', 'аналогичная', 'аналогичный',\n",
       "       'антимонопольщики', 'ао', 'апелляционных', 'арестованные',\n",
       "       'армения', 'аскарова', 'ассоциации', 'астана', 'ат', 'атырау',\n",
       "       'аудированной', 'аурум', 'байкенова', 'байтерек', 'бальчун',\n",
       "       'банком', 'банком20', 'банку', 'баст', 'батыры', 'бахтов',\n",
       "       'бахтова', 'бахыт', 'бахытбек', 'без', 'безболезненно',\n",
       "       'безопасности', 'бенефициаров', 'беспрецедентными', 'бизнес',\n",
       "       'бишимбаев', 'ближе', 'близких', 'боеготовность', 'боковой',\n",
       "       'болашак', 'более', 'больничные', 'борисбий', 'брифинге', 'будут',\n",
       "       'будущей', 'бузгул', 'бумаги', 'быть', 'бюджетный', 'бюджету',\n",
       "       'ващенко', 'вблизи', 'ввезенных', 'ведомств', 'ведущих',\n",
       "       'величину', 'вероятности', 'взаимоотношениях', 'взыскать',\n",
       "       'взятки', 'видеоматериалов', 'видны', 'виноград', 'властей',\n",
       "       'вложил', 'вложила', 'вмс', 'во', 'водворен', 'водителями',\n",
       "       'возбудило', 'возможность', 'возобновления', 'вопросах', 'восемь',\n",
       "       'восточный', 'вошел', 'время', 'вряд', 'все', 'всегда', 'всего',\n",
       "       'всей', 'всеобщее', 'всех', 'вт', 'второе', 'выборное', 'выделен',\n",
       "       'выделена', 'вызывает', 'выложили', 'выносимых', 'выполнены',\n",
       "       'выпуску', 'выпустили', 'выставлению', 'выстрелы', 'выступила',\n",
       "       'выход', 'выходные', 'выяснения', 'газетах', 'галиева', 'германии',\n",
       "       'главного', 'главы', 'говорит', 'год', 'года', 'годичной',\n",
       "       'городах', 'городе', 'городского', 'госдоходов', 'госпрограммы',\n",
       "       'государствами', 'государственной', 'готовит', 'готовятся',\n",
       "       'грабители', 'график', 'греко', 'грн', 'грузовых', 'даже', 'далее',\n",
       "       'данияру', 'данные', 'два', 'дважды', 'движении', 'движения',\n",
       "       'двух', 'дгд', 'девальвация', 'девочки', 'девушке', 'девяти',\n",
       "       'действий', 'действиях', 'действующая', 'декабре', 'декларацией',\n",
       "       'дела', 'деловой', 'денежный', 'денежных', 'деньги',\n",
       "       'департамента', 'депозитов', 'депозитом', 'детей', 'детищем',\n",
       "       'джакупов', 'дилеры', 'директора', 'дисквалификации', 'дкнб',\n",
       "       'для', 'дней', 'до', 'добавил', 'добавить', 'догадываясь',\n",
       "       'договоренности', 'доклад', 'долгами', 'должности', 'должностные',\n",
       "       'должностными', 'должностных', 'долларов', 'дом', 'дополнила',\n",
       "       'доступ', 'др', 'друзей', 'друзьями', 'души', 'его', 'единиц',\n",
       "       'единого', 'ежедневные', 'если', 'есть', 'жду', 'ждущие', 'же',\n",
       "       'железнодорожную', 'железнодорожным', 'женис', 'жизнь',\n",
       "       'жилищного', 'жилья', 'житикаре', 'за', 'забарный', 'забрать',\n",
       "       'заверили', 'завершено', 'загружены', 'задержали', 'задержание',\n",
       "       'задержанных', 'задерживаются', 'задолженность', 'заключили',\n",
       "       'законом', 'закрылись', 'зам', 'замедляется', 'заместитель',\n",
       "       'заметок', 'занимала', 'занимающий', 'запись', 'заплатила',\n",
       "       'запрещена', 'захватчиков', 'зачитала', 'заявили', 'заявку',\n",
       "       'заявляет', 'здесь', 'здравствуйте', 'земельного',\n",
       "       'злоупотреблении', 'игроку', 'из', 'избрал', 'известно',\n",
       "       'извинений', 'излом', 'измерительными', 'илья', 'инвестировании',\n",
       "       'инвестиционном', 'инвестиционную', 'инвестициям',\n",
       "       'индивидуальных', 'иностранных', 'инструментов',\n",
       "       'интересовавшимся', 'интерфакс', 'информации', 'информацию',\n",
       "       'информация', 'исполнительное', 'использование', 'история',\n",
       "       'источник', 'итогам', 'казакстан', 'казахстан', 'казахстана',\n",
       "       'казахстане', 'казахстанского', 'казинформ', 'казкоммерцбанк',\n",
       "       'казмунайгаз', 'как', 'какое', 'капшагайского', 'караганда',\n",
       "       'касается', 'качество', 'кгп', 'кенжебаева', 'китай', 'клети',\n",
       "       'кнб', 'когда', 'кожайбаев', 'количество', 'коллекторам',\n",
       "       'комитета', 'композитом', 'комфортные', 'конкретных',\n",
       "       'конкуренции', 'контактный', 'конце', 'кор242', 'корпоративному',\n",
       "       'коррупцией', 'коррупционная', 'космическими', 'которого',\n",
       "       'которой', 'которые', 'который', 'которым', 'которых', 'кредитов',\n",
       "       'кредитоспособности', 'кристина', 'критикует', 'кроме', 'ктж',\n",
       "       'ктк', 'ктэк', 'куандыка', 'куандыку', 'курсирующие', 'курсом',\n",
       "       'кыргызстан', 'лет', 'ли', 'либо', 'лимоны', 'лиц', 'лицензии',\n",
       "       'личные', 'лишились', 'людвиг', 'ляззат', 'магистрали',\n",
       "       'максимума', 'мальчик', 'маргулана', 'материальных', 'мать',\n",
       "       'махинациях', 'международной', 'мелочей', 'менеджеров',\n",
       "       'менеджером', 'мероприятиях', 'местном', 'место', 'металлы',\n",
       "       'метро', 'миллиард', 'минимально', 'минимум', 'министр',\n",
       "       'министра', 'минусы', 'мировой', 'мирсияпова', 'млн', 'млрд', 'мм',\n",
       "       'многодетных', 'многомиллиардных', 'могилевскому', 'могут',\n",
       "       'может', 'можно', 'мол', 'молча', 'московского', 'мошенничестве',\n",
       "       'мусайбеков', 'мухаири', 'мухамедиулы', 'мы', 'набегает',\n",
       "       'навсегда', 'нагрузки', 'над', 'надежности', 'надо', 'нажмите',\n",
       "       'назад', 'назарбаев', 'назначенное', 'наказание', 'накладываемых',\n",
       "       'наклонным', 'накопилась', 'накоплений', 'нам', 'намедни',\n",
       "       'нападения', 'написано', 'напомним', 'направленно', 'народным',\n",
       "       'населения', 'находятся', 'нацбанк', 'нацбанке', 'национального',\n",
       "       'национальной', 'национальный', 'национальным', 'начал',\n",
       "       'начальника', 'начато', 'начнет', 'не', 'невиновности', 'негатив',\n",
       "       'недавнее', 'недавняя', 'нежелания', 'незаконным', 'незрячую',\n",
       "       'неизбывная', 'ней', 'некоммерческая', 'некоторую',\n",
       "       'неосторожности', 'несырьевого', 'нефти', 'ниже', 'низкую',\n",
       "       'новаторское', 'новый', 'ногой', 'номинальной', 'ну', 'нужно',\n",
       "       'нурсултан', 'ныне', 'нұрлы', 'обвиняемые', 'обеспечения',\n",
       "       'обеспокоились', 'обесцениваются', 'области', 'облигации',\n",
       "       'облигаций', 'обойтись', 'образом', 'обратились', 'обратиться',\n",
       "       'обстоятельства', 'общего', 'общества', 'обществе', 'общественный',\n",
       "       'объем', 'объявлен', 'объясниться', 'обыск', 'одного', 'одобрили',\n",
       "       'оживления', 'ожидают', 'озвучивал', 'он', 'опирается',\n",
       "       'описанием', 'определить', 'оптимизмом', 'органами', 'организатор',\n",
       "       'организацией', 'организованы', 'ордабасы', 'орталык',\n",
       "       'освобождать', 'освобождена', 'основанием', 'оставались',\n",
       "       'оставили', 'остановке', 'осуществленным', 'осуществлено',\n",
       "       'осуществляет', 'осуществляя', 'от', 'ответственности', 'отвечают',\n",
       "       'отвечая', 'отказ', 'открыли', 'открытых', 'отменяли', 'отмечают',\n",
       "       'отношении', 'отправителя', 'отправке', 'отравляют', 'отрасли',\n",
       "       'отставку', 'отстранен', 'официальными', 'очевидца', 'очереди',\n",
       "       'очередь', 'падает', 'пандусы', 'партии', 'партнер', 'пассажирам',\n",
       "       'пассажирских', 'пассажирского', 'пенсионный', 'пенсионными',\n",
       "       'первом', 'переговоров', 'передает', 'переработке', 'пересмотреть',\n",
       "       'переспросил', 'период', 'писало', 'письма', 'платной', 'по',\n",
       "       'повысят', 'погасить', 'погибли', 'под', 'подали',\n",
       "       'подготовленному', 'поддержке', 'подешевели', 'подписан',\n",
       "       'подсудимого', 'пожизненно', 'пожизненным', 'позвонили', 'позже',\n",
       "       'позитивным', 'пока', 'показателей', 'политики', 'положены',\n",
       "       'положительном', 'полосу', 'получателей', 'получения', 'получить',\n",
       "       'понизило', 'попросила', 'популярных', 'портфеля',\n",
       "       'поручительства', 'посему', 'поскольку', 'последних', 'пост',\n",
       "       'пострадавших', 'пострадал', 'потеряли', 'потерянный', 'похищали',\n",
       "       'пошлина', 'поэтому', 'появиться', 'прав', 'правилами',\n",
       "       'правления', 'прага', 'практически', 'превышает',\n",
       "       'предварительному', 'преддверие', 'предложения', 'предоставляется',\n",
       "       'предпринимательскую', 'предприятия', 'председателя',\n",
       "       'представительский', 'преимущественно', 'премьера', 'пресс',\n",
       "       'преступления', 'преступная', 'приблизился', 'приватизировался',\n",
       "       'приветствуют', 'привлекли', 'приездом', 'признались', 'приличную',\n",
       "       'примет', 'природопользователей', 'пришло', 'проведения',\n",
       "       'проведены', 'проверка', 'проводящихся', 'прогнозов', 'продает',\n",
       "       'продаж', 'продали', 'продано', 'продать', 'продовольственными',\n",
       "       'продолжается', 'продуктам', 'продукции', 'проект', 'произошла',\n",
       "       'прокомментировали', 'промежутка', 'промышленность', 'проработал',\n",
       "       'просмотров', 'просто', 'протокол', 'профессиональную', 'проходил',\n",
       "       'процессе', 'прошлого', 'прошлом', 'путем', 'пшеничный', 'пять',\n",
       "       'работал', 'работе', 'работы', 'рабочая', 'раз', 'разборку',\n",
       "       'разве', 'развитие', 'развитию', 'развития', 'размещена',\n",
       "       'разнопланово', 'разочарование', 'рамках', 'ранее', 'расклад',\n",
       "       'расписана', 'расскажите', 'рассказали', 'расследования',\n",
       "       'рассматриваемый', 'рассматривать', 'рассчитать', 'реализовывался',\n",
       "       'регионы', 'регистраций', 'резонанс', 'результате', 'рейтинги',\n",
       "       'рейтингов', 'рекалибровку', 'республике', 'республики', 'ресурсы',\n",
       "       'рет', 'рецессия', 'решение', 'решив', 'родственники', 'розыске',\n",
       "       'россия', 'ростом', 'руководитель', 'руководство', 'рынок',\n",
       "       'сагинтаева', 'сакен', 'сами', 'самый', 'саранская', 'сариев',\n",
       "       'сбережений', 'сборов', 'сбоя', 'светло', 'свидетелем', 'свое',\n",
       "       'свою', 'связи', 'сговору', 'сделать', 'сделок', 'сдержанными',\n",
       "       'сегодня', 'сегодняшним', 'сейчас', 'сектора', 'семей', 'сентябре',\n",
       "       'сентябрем', 'сентябрь', 'сентября', 'сергея', 'сжатые',\n",
       "       'сжиганию', 'систематические', 'ситуацию', 'скачу', 'скоро',\n",
       "       'скоростей', 'скорости', 'слабыми', 'следственные', 'следственных',\n",
       "       'следующих', 'сложилось', 'сложность', 'служб', 'служба', 'службу',\n",
       "       'служебное', 'слышат', 'смогло', 'снижение', 'снятое', 'со',\n",
       "       'соблюдался', 'собой', 'собственника', 'собственные',\n",
       "       'собственными', 'совершении', 'совершил', 'совета', 'советом',\n",
       "       'совсем', 'совхоза', 'сокращаются', 'сомнительной', 'сообщает',\n",
       "       'сообщали', 'сообщении', 'сообщению', 'сообщил', 'сообщила',\n",
       "       'сообщили', 'соответственно', 'соответствует', 'соревнований',\n",
       "       'составил', 'составит', 'состоялась', 'сотрудничестве',\n",
       "       'сохраняются', 'социальных', 'соцразвития', 'союз', 'спад',\n",
       "       'специальная', 'сплошная', 'спорт', 'спортсмена', 'спорту',\n",
       "       'спровоцировать', 'спуститься', 'средств', 'срок', 'сроки', 'ст',\n",
       "       'стал', 'стали', 'стандартов', 'стартовал', 'стоит', 'страна',\n",
       "       'студенты', 'субсидирование', 'субсидирования', 'субъективным',\n",
       "       'субъекты', 'суд', 'суда', 'судьей', 'сумму', 'сферы', 'схему',\n",
       "       'схемы', 'сход', 'схода', 'счет', 'считать', 'так', 'также',\n",
       "       'такие', 'там', 'таможенники', 'таможенной', 'таможенных', 'тариф',\n",
       "       'текущего', 'текущем', 'тем', 'тенге', 'теперь', 'тепловоз',\n",
       "       'терсаканский', 'тесты', 'того', 'только', 'том', 'тонн', 'тоо',\n",
       "       'торговый', 'тоссела', 'точную', 'тратил', 'требованием',\n",
       "       'требования', 'требованиям', 'тремя', 'троса', 'тут', 'тыс',\n",
       "       'тысяч', 'тэц', 'убытках', 'уведомил', 'уведомление', 'уволены',\n",
       "       'удержанию', 'улицы', 'улучшиться', 'униан', 'универсала',\n",
       "       'уплата', 'управлении', 'управлять', 'управляющие', 'уровне',\n",
       "       'условия', 'успокаивают', 'уставный', 'устойчивости', 'утра',\n",
       "       'участниц', 'фактам', 'физических', 'физкультурно', 'финального',\n",
       "       'финансовых', 'фининститута', 'финрегулятор', 'фонд', 'фонда',\n",
       "       'формирование', 'фото', 'характерно', 'хиджра', 'ходатайствам',\n",
       "       'ходе', 'хорошо', 'хотелось', 'хромым', 'царской', 'цвета',\n",
       "       'целом', 'цель', 'центра', 'центркредит', 'цены', 'часов', 'части',\n",
       "       'часть', 'человек', 'через', 'чиновники', 'чиновников', 'числе',\n",
       "       'чтении', 'что', 'чтобы', 'чужим', 'шамши', 'шкур', 'штрафа',\n",
       "       'шымкента', 'шымкенте', 'экономики', 'экспедиторскими',\n",
       "       'экспертами', 'экспертов', 'эксплуатацию', 'электричество',\n",
       "       'электрогенерирующей', 'электронные', 'эльдара', 'эльдаром',\n",
       "       'эмигрировал', 'энергоорталык', 'это', 'этого', 'этой', 'этом',\n",
       "       'юридический', 'юридических', 'является', 'яда', 'январь', 'ііі'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#выполняем те же самые действия, но для двух классов\n",
    "rnd_clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "rnd_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred2 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred2)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred2))\n",
    "print(rnd_clf.feature_importances_)\n",
    "print(rnd_clf.predict_proba(X_test))\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred2))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['RandomForestClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766666666666667\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18539103 0.81460897]\n",
      " [0.17543108 0.82456892]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1736363  0.8263637 ]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17087393 0.82912607]\n",
      " [0.19209775 0.80790225]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17535878 0.82464122]\n",
      " [0.19868684 0.80131316]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.17545027 0.82454973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.1837764  0.8162236 ]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17044786 0.82955214]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17486922 0.82513078]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17044786 0.82955214]\n",
      " [0.17213139 0.82786861]\n",
      " [0.18878441 0.81121559]\n",
      " [0.17543108 0.82456892]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17213139 0.82786861]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18878129 0.81121871]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17549168 0.82450832]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.1670427  0.8329573 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17240291 0.82759709]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544305 0.82455695]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18798928 0.81201072]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210732 0.82789268]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544545 0.82455455]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18382025 0.81617975]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18875962 0.81124038]\n",
      " [0.1736363  0.8263637 ]\n",
      " [0.32033514 0.67966486]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18382025 0.81617975]\n",
      " [0.17290299 0.82709701]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17087393 0.82912607]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.18382025 0.81617975]\n",
      " [0.16711212 0.83288788]\n",
      " [0.20322317 0.79677683]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17869693 0.82130307]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17549168 0.82450832]\n",
      " [0.17087393 0.82912607]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17709535 0.82290465]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.18710018 0.81289982]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18376683 0.81623317]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.18044066 0.81955934]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18986524 0.81013476]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544545 0.82455455]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16809661 0.83190339]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17295267 0.82704733]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18876203 0.81123797]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.213141   0.786859  ]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1812836  0.8187164 ]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.21205251 0.78794749]\n",
      " [0.20040958 0.79959042]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18047298 0.81952702]\n",
      " [0.17045027 0.82954973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19713922 0.80286078]\n",
      " [0.1887837  0.8112163 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.172854   0.827146  ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17045027 0.82954973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19215056 0.80784944]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19395936 0.80604064]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.20039766 0.79960234]\n",
      " [0.16984995 0.83015005]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17542157 0.82457843]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        37\n",
      "          1       0.88      1.00      0.93       263\n",
      "\n",
      "avg / total       0.77      0.88      0.82       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['000', '01', '03', ..., 'январе', 'января', 'қазына'], dtype='<U32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ext_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "ext_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(ExtraTreesClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred3 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred3)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred3))\n",
    "print(ext_clf.feature_importances_)\n",
    "print(ext_clf.predict_proba(X_test))\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred3))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['ExtraTreesClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.27      0.06      0.10        52\n",
      "          1       0.83      0.97      0.89       248\n",
      "\n",
      "avg / total       0.73      0.81      0.76       300\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['10', '100', '11', '13', '2012', '2015', '2016', '2016г', '22',\n",
       "       '25', '28', '30', '52', '60', 'auto', 'bombardier', 'cs300',\n",
       "       'enpf', 'invest', 'kase', 'kegoc', 'kookmin', 'lada', 'mega',\n",
       "       'rusal', 'zakon', 'авиакомпании', 'авиационного', 'азия', 'акишев',\n",
       "       'акций', 'алматинской', 'алматы', 'ао', 'астана', 'байтерек',\n",
       "       'банк', 'безопасности', 'бизнес', 'бизнеса', 'бишимбаев', 'блох',\n",
       "       'будут', 'был', 'были', 'вв', 'ведомстве', 'вице', 'вич',\n",
       "       'вконтакте', 'вокзале', 'все', 'встречи', 'где', 'глава', 'года',\n",
       "       'году', 'города', 'гривень', 'даже', 'данный', 'двд', 'двое',\n",
       "       'дела', 'дело', 'денег', 'деньги', 'директоров', 'для', 'до',\n",
       "       'долг', 'должен', 'дома', 'евразийский', 'его', 'ед', 'енпф',\n",
       "       'еще', 'же', 'завод', 'заместитель', 'иванов', 'из', 'изменения',\n",
       "       'им', 'именно', 'имеют', 'интер', 'информацию', 'итогам', 'их',\n",
       "       'казахстан', 'казахстана', 'казахстане', 'казахстанской',\n",
       "       'казинвестбанке', 'как', 'ккм', 'кнб', 'кокшетау', 'количество',\n",
       "       'компания', 'корреспондент', 'коррупции', 'коррупционных',\n",
       "       'которую', 'кредит', 'кредитные', 'кск', 'ктга', 'ктж', 'курс',\n",
       "       'ли', 'лица', 'менее', 'меры', 'месте', 'млн', 'мужчина', 'мы',\n",
       "       'на', 'навального', 'накоплений', 'нацбанк', 'нацбанке',\n",
       "       'национальной', 'нацфонда', 'ндс', 'не', 'них', 'но', 'области',\n",
       "       'около', 'она', 'они', 'оружием', 'от', 'отделения', 'отношении',\n",
       "       'очень', 'пака', 'пенсионные', 'пенсионный', 'поводу', 'поезд',\n",
       "       'показателей', 'порядка', 'после', 'поэтому', 'прав',\n",
       "       'предпринимательства', 'президент', 'пресс', 'при', 'проверки',\n",
       "       'прогноз', 'продажи', 'продукции', 'проекта', 'производство',\n",
       "       'произошел', 'работы', 'раз', 'развитию', 'развития', 'размере',\n",
       "       'рао', 'результате', 'рк', 'россии', 'рост', 'роста',\n",
       "       'руководители', 'руководитель', 'сайта', 'свою', 'себе', 'сейчас',\n",
       "       'сетевой', 'системы', 'сказал', 'словам', 'службы', 'снижение',\n",
       "       'собственных', 'совета', 'согласно', 'сообщает', 'среди', 'страны',\n",
       "       'суд', 'суде', 'судья', 'сфере', 'так', 'текущего', 'тенге',\n",
       "       'терентьев', 'территории', 'то', 'того', 'только', 'тоо', 'уже',\n",
       "       'управление', 'управления', 'услуги', 'утечек', 'утилизации',\n",
       "       'участке', 'факту', 'финансовых', 'ходе', 'цена', 'частности',\n",
       "       'человек', 'что', 'чтобы', 'шасси', 'шахте', 'шымбулак',\n",
       "       'экспертов', 'этого', 'января'], dtype='<U30')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('LogisticRegression', LogisticRegression(penalty='l1'))]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'C': list(range(1, 5)), 'penalty': ['l1', 'l2']}\n",
    "grid_search_cv = GridSearchCV(LogisticRegression(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred4 = grid_search_cv.predict(X_test)\n",
    "print(accuracy_score(dataY_test, y_pred4))\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred4))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['LogisticRegression'].coef_ != 0)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с бинарной классификацией лучшим по точности оказался классификатор Random Forest. (accuracy = 0.826667)\n",
    "\n",
    "Можно заметить, что хоть и большинство слов, на которые опирается модель, определяя тональность, схожи, есть также и различные слова для каждого случая. Также среди слов, на которые модель обращает внимание, встречается очень много лишних слов, которые, по сути, не должны влиять на определение тональности текста, например, часто встречающиеся слова в целом, числительные или предлоги."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 5\n",
    "\n",
    "Попробуем изменить схему препроцессинга. Проведем лемматизацию атрибутов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json('train.json', encoding = 'utf-8')\n",
    "data.head(10)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = {'negative': -1, 'neutral': 0, 'positive': 1} \n",
    "data['y'] = data['sentiment'].map(lambda x: y[x])\n",
    "\n",
    "data_Y = data['y'].values\n",
    "data_X = data['text'].values\n",
    "\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = train_test_split(data_Y, data_X, test_size=0.3, shuffle=True)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = dataY_train[:700], dataY_test[:300], dataX_train[:700], dataX_test[:300]\n",
    "\n",
    "#преобразуем наши тексты в списки слов\n",
    "X_train = []\n",
    "for x in dataX_train:\n",
    "    x = x.split()\n",
    "    X_train.append(x)\n",
    "    \n",
    "X_test = []\n",
    "for x in dataX_test:\n",
    "    x = x.split()\n",
    "    X_test.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "X_train_l = []\n",
    "X_test_l = []\n",
    "\n",
    "#пройдем по каждому слову и вместо него возьмем его начальную форму\n",
    "for text in X_train:\n",
    "    lemmas = []\n",
    "    for word in text:\n",
    "        p = morph.parse(word)[0]\n",
    "        lemmas.append(p.normal_form)\n",
    "    X_train_l.append(lemmas)\n",
    "for text in X_test:\n",
    "    lemmas = []\n",
    "    for word in text:\n",
    "        p = morph.parse(word)[0]\n",
    "        lemmas.append(p.normal_form)\n",
    "    X_test_l.append(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['монополист', 'объявить', 'о', '50%', 'скидка', 'на', 'путешествие', '31', 'декабря,', 'сообщать', 'портал', 'мой', 'город.', '«ао', '«пассажирский', 'перевозки»', 'в', 'преддверие', 'новое', 'год', 'объявить', 'скидка', 'на', 'скоростной', 'поезд', '«тулпар-тальго».', 'как', 'сказать', 'на', 'они', 'сайте,', 'на', 'весь', 'поезд', '«тулпар-тальго»', '(кром', 'поезд', '№', '3/4', 'астан', '—', 'алматы,', '№', '25/26', 'алматы', '—', 'шымкент)', 'с', 'отправление', '31', 'декабрь', 'билет', 'можно', 'быть', 'приобрести', 'в', 'два', 'раз', 'дешевле.', 'например,', 'билет', 'на', 'поезд', '№', '701/702,', '№', '706/705', 'сообщение', 'астан', '—', 'алматы', 'на', '31', 'декабрь', 'быть', 'стоить', 'от', '6', '000', 'тенге,', 'шымкент', '—', 'астан', '—', 'от', '5', '500', 'тенге,', 'кызылорд', '—', 'астан', '—', 'от', '8', '500', 'тенге,', 'астан', '—', 'защита', '—', 'от', '5', '300', 'тенге,', 'алматы', '—', 'защита', '—', 'от', '4', '900', 'тенге,', 'алматы', '—', 'петропавловск', '—', 'от', '7', '700', 'тенге.', 'однако', 'железнодорожник', 'предупредили,', 'что', 'близкий', 'к', 'дата', 'отправление', 'поезд', 'и', 'при', 'увеличение', 'спрос', 'стоимость', 'билет', 'быть', 'расти.']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_l[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также очистим тексты от стоп-слов, используя nltk. Кроме стоп-слов из nltk удалим еще числительные, поскольку они тоже иногда препятствуют правильному определению тональности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for text in X_train_l:\n",
    "    for word in text:\n",
    "        if word in stopwords.words('russian') or word.isdigit() == True: \n",
    "            text.remove(word)\n",
    "    \n",
    "for text in X_test_l:\n",
    "    for word in text:\n",
    "        if word in stopwords.words('russian') or word.isdigit() == True:\n",
    "            text.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['монополист', 'объявить', '50%', 'скидка', 'путешествие', 'декабря,', 'сообщать', 'портал', 'город.', '«ао', '«пассажирский', 'перевозки»', 'преддверие', 'новое', 'год', 'объявить', 'скидка', 'скоростной', 'поезд', '«тулпар-тальго».', 'сказать', 'они', 'сайте,', 'весь', 'поезд', '«тулпар-тальго»', '(кром', 'поезд', '№', '3/4', 'астан', '—', 'алматы,', '№', '25/26', 'алматы', '—', 'шымкент)', 'отправление', 'декабрь', 'билет', 'приобрести', 'два', 'дешевле.', 'например,', 'билет', 'поезд', '№', '701/702,', '№', '706/705', 'сообщение', 'астан', '—', 'алматы', '31', 'декабрь', 'стоить', '6', 'тенге,', 'шымкент', '—', 'астан', '—', '5', 'тенге,', 'кызылорд', '—', 'астан', '—', '8', 'тенге,', 'астан', '—', 'защита', '—', '5', 'тенге,', 'алматы', '—', 'защита', '—', '4', 'тенге,', 'алматы', '—', 'петропавловск', '—', '7', 'тенге.', 'однако', 'железнодорожник', 'предупредили,', 'близкий', 'дата', 'отправление', 'поезд', 'при', 'увеличение', 'спрос', 'стоимость', 'билет', 'быть', 'расти.']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_l[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#преобразуем списки слов снова в тексты, чтобы вернуться к исходной форме\n",
    "X_train_l_new = []\n",
    "X_test_l_new = []\n",
    "\n",
    "for text in X_train_l:\n",
    "    text_str = \" \".join(text)\n",
    "    X_train_l_new.append(text_str)\n",
    "    \n",
    "for text in X_test_l:\n",
    "    text_str = \" \".join(text)\n",
    "    X_test_l_new.append(text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['астана. казинформ - президент казахстан нурсултан назарбаев выразить недовольство работа создание условие инвесторов. это заявить сегодня ход расширить заседание правительства, передавать корреспондент миа «казинформ». глава государство отметил, министерство инвестиция развитие являться ответственный вопрос привлечение инвестор продвижение экспорта. «ты же, я провозить встреча «капитан бизнеса» весь страна был. недавно саудовский аравия были, эмиратах, это японии, южный корее, америке. я это делаю. весь проявлять большой заинтересованность казахстану. когда приходить сюда (потенциальный инвестор - прим. автора), встречаться. никто решать вопросы. приезжать говорят, наш ребёнок учится, лечится, делать? должный показать им, у казахстан создать весь условие инвесторов», - сказать нурсултан назарбаев, обращаться глава мир жениса касымбеку. вместе тем глава государство поручить привести в порядок работа продвижение экспорта. «быть государства, который мы сейчас работаем. этот работа привести в порядок. это вопрос с министр иностранный дело абдрахманов должный заключить себя договор - посольство сопровождать приходящий инвесторов, посольство быть следить, наш экспорт идти туда», - добавить нурсултан назарбаев.']\n"
     ]
    }
   ],
   "source": [
    "print(X_test_l_new[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 6\n",
    "\n",
    "Попробуем повторить то, что было сделано в задаче 4, и посмотрим, какие результаты теперь покажут классификаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 0, lowercase = True) \n",
    "vectorizer.fit(X_train_l_new)\n",
    "X_train = vectorizer.transform(X_train_l_new).toarray()\n",
    "\n",
    "test_vectorizer = CountVectorizer(min_df = 0, lowercase = True, vocabulary=vectorizer.vocabulary_) \n",
    "test_vectorizer.fit(X_test_l_new)\n",
    "X_test = vectorizer.transform(X_test_l_new).toarray()\n",
    "\n",
    "print(X_train[:10])\n",
    "print(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5633333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "linsvc_clf = LinearSVC(C=5, loss=\"hinge\", penalty = 'l2', multi_class = 'ovr')\n",
    "\n",
    "param_grid = {'C': list(range(1, 5)), 'loss': ['hinge', 'squared_hinge']}\n",
    "grid_search_cv = GridSearchCV(LinearSVC(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred1 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred1)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC не улучшил показатель точности. Наоборот, значение accuracy слегка снизилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4633333333333333\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.16329369 0.48942821 0.3472781 ]\n",
      " [0.17107837 0.48446587 0.34445577]\n",
      " [0.18208728 0.49078546 0.32712725]\n",
      " [0.16405509 0.49501811 0.34092679]\n",
      " [0.16712357 0.48274948 0.35012696]\n",
      " [0.16298725 0.49216888 0.34484387]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.17173444 0.49057179 0.33769377]\n",
      " [0.17039799 0.49511649 0.33448552]\n",
      " [0.16031051 0.48801273 0.35167675]\n",
      " [0.16125158 0.5076699  0.33107853]\n",
      " [0.1512482  0.49554885 0.35320295]\n",
      " [0.17365487 0.49670907 0.32963606]\n",
      " [0.16447747 0.49914479 0.33637774]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.20909574 0.4688521  0.32205216]\n",
      " [0.17418459 0.49549219 0.33032322]\n",
      " [0.16135264 0.49595681 0.34269055]\n",
      " [0.2707198  0.46203295 0.26724725]\n",
      " [0.16912015 0.49404501 0.33683483]\n",
      " [0.16911379 0.4913258  0.33956041]\n",
      " [0.17178251 0.4810213  0.34719619]\n",
      " [0.16453734 0.49022536 0.3452373 ]\n",
      " [0.16433864 0.48880387 0.34685749]\n",
      " [0.16818285 0.49855751 0.33325964]\n",
      " [0.163631   0.48290491 0.35346409]\n",
      " [0.1584973  0.48881177 0.35269093]\n",
      " [0.16447605 0.4830582  0.35246575]\n",
      " [0.16181682 0.50432991 0.33385327]\n",
      " [0.17400719 0.48834833 0.33764448]\n",
      " [0.17337795 0.49448001 0.33214204]\n",
      " [0.16388536 0.50716492 0.32894972]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.1584973  0.48881177 0.35269093]\n",
      " [0.16090274 0.47122068 0.36787658]\n",
      " [0.16469499 0.49678854 0.33851647]\n",
      " [0.173519   0.4912458  0.3352352 ]\n",
      " [0.16579429 0.49361559 0.34059013]\n",
      " [0.16548895 0.48577334 0.34873771]\n",
      " [0.16342271 0.47350792 0.36306937]\n",
      " [0.17327897 0.48300027 0.34372076]\n",
      " [0.14813058 0.4627509  0.38911852]\n",
      " [0.14943747 0.46618891 0.38437362]\n",
      " [0.16919493 0.50338649 0.32741858]\n",
      " [0.18156907 0.49105512 0.32737581]\n",
      " [0.15799562 0.48254891 0.35945546]\n",
      " [0.15511914 0.50107531 0.34380554]\n",
      " [0.15715623 0.49641978 0.34642399]\n",
      " [0.18395414 0.48373381 0.33231206]\n",
      " [0.16526917 0.46310623 0.3716246 ]\n",
      " [0.16334192 0.49629853 0.34035954]\n",
      " [0.16836666 0.49005839 0.34157495]\n",
      " [0.15489439 0.49266525 0.35244036]\n",
      " [0.16687249 0.48831182 0.3448157 ]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.16800614 0.50977988 0.32221398]\n",
      " [0.15787274 0.47604511 0.36608215]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.15832965 0.48766838 0.35400197]\n",
      " [0.15284543 0.46740932 0.37974525]\n",
      " [0.16117015 0.49886668 0.33996317]\n",
      " [0.17571867 0.49433636 0.32994497]\n",
      " [0.14448109 0.46544729 0.39007162]\n",
      " [0.17460075 0.46850973 0.35688952]\n",
      " [0.1635051  0.49278778 0.34370712]\n",
      " [0.1668369  0.49221686 0.34094624]\n",
      " [0.16973287 0.50355815 0.32670898]\n",
      " [0.17242002 0.49175906 0.33582092]\n",
      " [0.15548428 0.4770992  0.36741652]\n",
      " [0.2005586  0.48101914 0.31842226]\n",
      " [0.16778599 0.49973522 0.33247879]\n",
      " [0.16019064 0.48037557 0.35943379]\n",
      " [0.15421568 0.47930065 0.36648368]\n",
      " [0.16427747 0.47024002 0.36548251]\n",
      " [0.21037554 0.47341673 0.31620773]\n",
      " [0.16016274 0.49444294 0.34539431]\n",
      " [0.17537102 0.49293421 0.33169478]\n",
      " [0.16527956 0.49487866 0.33984178]\n",
      " [0.16747463 0.48866613 0.34385924]\n",
      " [0.17705338 0.48551965 0.33742697]\n",
      " [0.155257   0.47868407 0.36605893]\n",
      " [0.16019181 0.50463877 0.33516942]\n",
      " [0.15274373 0.49445571 0.35280056]\n",
      " [0.15910813 0.49022443 0.35066743]\n",
      " [0.16637633 0.49892305 0.33470061]\n",
      " [0.18374742 0.47837623 0.33787635]\n",
      " [0.15785224 0.4723573  0.36979046]\n",
      " [0.19283194 0.48061895 0.32654912]\n",
      " [0.16338603 0.48568167 0.3509323 ]\n",
      " [0.15231582 0.52756021 0.32012397]\n",
      " [0.18755249 0.4814927  0.3309548 ]\n",
      " [0.15768006 0.47428011 0.36803984]\n",
      " [0.16300867 0.48586988 0.35112146]\n",
      " [0.15965011 0.48449376 0.35585613]\n",
      " [0.15907394 0.49421764 0.34670842]\n",
      " [0.1750914  0.48694304 0.33796556]\n",
      " [0.15368613 0.4731309  0.37318298]\n",
      " [0.16189638 0.50388517 0.33421844]\n",
      " [0.16853944 0.50004565 0.33141491]\n",
      " [0.15804955 0.49304117 0.34890928]\n",
      " [0.16433563 0.49547392 0.34019045]\n",
      " [0.16450837 0.48109726 0.35439437]\n",
      " [0.16836185 0.49234137 0.33929678]\n",
      " [0.13475149 0.57856057 0.28668794]\n",
      " [0.16984306 0.47067281 0.35948413]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.1650085  0.48786795 0.34712355]\n",
      " [0.17644556 0.51052967 0.31302478]\n",
      " [0.16662987 0.49327931 0.34009082]\n",
      " [0.19349741 0.48986176 0.31664082]\n",
      " [0.15921672 0.48590905 0.35487422]\n",
      " [0.16331998 0.48230362 0.3543764 ]\n",
      " [0.15953394 0.491863   0.34860306]\n",
      " [0.16527956 0.49487866 0.33984178]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.16391179 0.47353986 0.36254836]\n",
      " [0.16175366 0.47514099 0.36310536]\n",
      " [0.17052405 0.49506509 0.33441085]\n",
      " [0.15341783 0.48318112 0.36340105]\n",
      " [0.16405509 0.49501811 0.34092679]\n",
      " [0.15553653 0.47066829 0.37379518]\n",
      " [0.27400293 0.45763536 0.2683617 ]\n",
      " [0.17361188 0.46462912 0.36175899]\n",
      " [0.16159785 0.48945522 0.34894693]\n",
      " [0.16975097 0.49072403 0.339525  ]\n",
      " [0.16260436 0.48085631 0.35653933]\n",
      " [0.16452657 0.49360711 0.34186631]\n",
      " [0.15816766 0.48645602 0.35537631]\n",
      " [0.17722403 0.4843506  0.33842537]\n",
      " [0.15733832 0.48015627 0.36250541]\n",
      " [0.14816294 0.50322941 0.34860765]\n",
      " [0.16172549 0.47425082 0.36402369]\n",
      " [0.1681927  0.4800502  0.35175711]\n",
      " [0.16331225 0.4868811  0.34980666]\n",
      " [0.17780758 0.49516859 0.32702383]\n",
      " [0.18504074 0.49603833 0.31892093]\n",
      " [0.16346694 0.48280354 0.35372952]\n",
      " [0.17682897 0.49917689 0.32399414]\n",
      " [0.17115317 0.48821706 0.34062976]\n",
      " [0.16706211 0.50216963 0.33076827]\n",
      " [0.15192286 0.47041761 0.37765953]\n",
      " [0.1620016  0.4798683  0.3581301 ]\n",
      " [0.16106694 0.48139962 0.35753344]\n",
      " [0.17542423 0.48752891 0.33704686]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.16039577 0.48003577 0.35956846]\n",
      " [0.16462725 0.48720003 0.34817272]\n",
      " [0.17304548 0.49006987 0.33688465]\n",
      " [0.1595015  0.50111838 0.33938011]\n",
      " [0.15899953 0.49487812 0.34612235]\n",
      " [0.18702581 0.48627133 0.32670286]\n",
      " [0.16017353 0.49502872 0.34479775]\n",
      " [0.15868457 0.48262725 0.35868818]\n",
      " [0.1645032  0.49511952 0.34037728]\n",
      " [0.16620739 0.48814928 0.34564333]\n",
      " [0.16673653 0.50824477 0.32501869]\n",
      " [0.16036507 0.49393813 0.3456968 ]\n",
      " [0.15610186 0.48947761 0.35442053]\n",
      " [0.16661267 0.49477378 0.33861355]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.15977863 0.48385586 0.35636551]\n",
      " [0.16905836 0.50638102 0.32456062]\n",
      " [0.1679763  0.48884097 0.34318273]\n",
      " [0.1931265  0.50777821 0.29909528]\n",
      " [0.16296134 0.47923045 0.35780821]\n",
      " [0.16433864 0.48880387 0.34685749]\n",
      " [0.16281599 0.4911487  0.3460353 ]\n",
      " [0.16562991 0.48853409 0.34583599]\n",
      " [0.18892197 0.47839036 0.33268767]\n",
      " [0.16491094 0.4695338  0.36555526]\n",
      " [0.16318784 0.49548189 0.34133027]\n",
      " [0.1614256  0.48546795 0.35310645]\n",
      " [0.16375557 0.49730023 0.3389442 ]\n",
      " [0.16548895 0.48577334 0.34873771]\n",
      " [0.16334192 0.49629853 0.34035954]\n",
      " [0.15701763 0.48768702 0.35529535]\n",
      " [0.16704153 0.49247337 0.3404851 ]\n",
      " [0.16159283 0.50302182 0.33538535]\n",
      " [0.23293233 0.47762744 0.28944022]\n",
      " [0.15137056 0.46990509 0.37872435]\n",
      " [0.16493955 0.50899638 0.32606407]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.15968025 0.50784647 0.33247328]\n",
      " [0.16217086 0.47661475 0.36121439]\n",
      " [0.16620868 0.49777967 0.33601165]\n",
      " [0.15570888 0.48198181 0.36230931]\n",
      " [0.1626944  0.48104369 0.35626191]\n",
      " [0.16637633 0.49892305 0.33470061]\n",
      " [0.16748328 0.49258507 0.33993165]\n",
      " [0.17470437 0.50371929 0.32157635]\n",
      " [0.1636377  0.50095615 0.33540614]\n",
      " [0.16370311 0.48838655 0.34791033]\n",
      " [0.16757036 0.48564257 0.34678707]\n",
      " [0.17140506 0.48158768 0.34700726]\n",
      " [0.16836666 0.49005839 0.34157495]\n",
      " [0.16387039 0.49368441 0.3424452 ]\n",
      " [0.15633832 0.4636332  0.38002848]\n",
      " [0.23310411 0.45803776 0.30885812]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.16296566 0.50230734 0.334727  ]\n",
      " [0.16364822 0.48911574 0.34723603]\n",
      " [0.16469162 0.49551072 0.33979766]\n",
      " [0.16802575 0.48047493 0.35149932]\n",
      " [0.16969524 0.49219566 0.33810909]\n",
      " [0.16527956 0.49487866 0.33984178]\n",
      " [0.1704088  0.49091596 0.33867523]\n",
      " [0.15816194 0.48818051 0.35365755]\n",
      " [0.15346382 0.4992955  0.34724068]\n",
      " [0.16454108 0.49518717 0.34027175]\n",
      " [0.16811381 0.49227045 0.33961574]\n",
      " [0.15886974 0.49963263 0.34149763]\n",
      " [0.16518115 0.49677642 0.33804243]\n",
      " [0.16401372 0.48522706 0.35075922]\n",
      " [0.21169933 0.47653702 0.31176364]\n",
      " [0.17204736 0.49828851 0.32966414]\n",
      " [0.15950196 0.48940495 0.35109309]\n",
      " [0.16183184 0.48627542 0.35189274]\n",
      " [0.16854626 0.4952466  0.33620714]\n",
      " [0.1599043  0.48012542 0.35997028]\n",
      " [0.15648955 0.46915526 0.3743552 ]\n",
      " [0.15648129 0.47777047 0.36574825]\n",
      " [0.16365244 0.48635974 0.34998782]\n",
      " [0.15953394 0.491863   0.34860306]\n",
      " [0.16905774 0.49167519 0.33926707]\n",
      " [0.16458367 0.49554484 0.33987149]\n",
      " [0.16922559 0.48495263 0.34582178]\n",
      " [0.1584973  0.48881177 0.35269093]\n",
      " [0.1635487  0.49623704 0.34021426]\n",
      " [0.16424291 0.49182743 0.34392966]\n",
      " [0.14448109 0.46544729 0.39007162]\n",
      " [0.17447279 0.48766915 0.33785806]\n",
      " [0.19392067 0.49157554 0.3145038 ]\n",
      " [0.16388854 0.4675662  0.36854526]\n",
      " [0.15863822 0.50086081 0.34050097]\n",
      " [0.15741473 0.49331387 0.3492714 ]\n",
      " [0.16137158 0.49127197 0.34735645]\n",
      " [0.16701601 0.5003964  0.33258759]\n",
      " [0.1693013  0.50323264 0.32746606]\n",
      " [0.16691591 0.49515446 0.33792963]\n",
      " [0.16605035 0.49529596 0.33865369]\n",
      " [0.17953798 0.49739338 0.32306863]\n",
      " [0.1917372  0.47803572 0.33022707]\n",
      " [0.16121982 0.50039668 0.3383835 ]\n",
      " [0.16905266 0.48875107 0.34219627]\n",
      " [0.16940118 0.45795436 0.37264446]\n",
      " [0.15910854 0.49524947 0.34564199]\n",
      " [0.13810326 0.45945564 0.4024411 ]\n",
      " [0.17271673 0.4875297  0.33975358]\n",
      " [0.15827206 0.50777375 0.33395419]\n",
      " [0.17027099 0.49729024 0.33243877]\n",
      " [0.16189057 0.48491005 0.35319938]\n",
      " [0.163189   0.49727287 0.33953814]\n",
      " [0.16648894 0.4968413  0.33666977]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.19581708 0.48730315 0.31687977]\n",
      " [0.16043102 0.47775035 0.36181863]\n",
      " [0.15933431 0.48826157 0.35240412]\n",
      " [0.16040912 0.48334256 0.35624832]\n",
      " [0.16091406 0.5068477  0.33223824]\n",
      " [0.16347311 0.49032974 0.34619715]\n",
      " [0.17398077 0.50686445 0.31915478]\n",
      " [0.18430943 0.48490865 0.33078193]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.16659398 0.49088559 0.34252043]\n",
      " [0.13852856 0.47496118 0.38651026]\n",
      " [0.18179646 0.50698698 0.31121656]\n",
      " [0.16301368 0.48607241 0.35091391]\n",
      " [0.16213434 0.48568566 0.35218   ]\n",
      " [0.15424841 0.48426331 0.36148828]\n",
      " [0.19086985 0.49160323 0.31752692]\n",
      " [0.16363214 0.49157043 0.34479743]\n",
      " [0.17475974 0.4929039  0.33233636]\n",
      " [0.15951222 0.48106535 0.35942243]\n",
      " [0.17599216 0.47914303 0.34486481]\n",
      " [0.15637256 0.50563594 0.3379915 ]\n",
      " [0.1679763  0.48884097 0.34318273]\n",
      " [0.1606162  0.48054792 0.35883588]\n",
      " [0.16446335 0.49050374 0.34503291]\n",
      " [0.16246776 0.49171694 0.3458153 ]\n",
      " [0.1709141  0.49409777 0.33498813]\n",
      " [0.16527956 0.49487866 0.33984178]\n",
      " [0.16190297 0.48619657 0.35190046]\n",
      " [0.15797556 0.48437698 0.35764746]\n",
      " [0.16524758 0.49242061 0.34233181]\n",
      " [0.19717253 0.50376413 0.29906334]\n",
      " [0.16902576 0.48921714 0.3417571 ]\n",
      " [0.17179816 0.49455792 0.33364391]\n",
      " [0.16904004 0.50560115 0.32535881]\n",
      " [0.15536712 0.47842945 0.36620343]\n",
      " [0.15725334 0.48601587 0.35673079]\n",
      " [0.16864695 0.49040269 0.34095036]\n",
      " [0.21386964 0.47361112 0.31251924]\n",
      " [0.16527956 0.49487866 0.33984178]\n",
      " [0.16540767 0.48274507 0.35184725]\n",
      " [0.17494067 0.48860628 0.33645304]\n",
      " [0.16299895 0.48903154 0.34796951]\n",
      " [0.17317371 0.49504921 0.33177708]\n",
      " [0.16424291 0.49182743 0.34392966]\n",
      " [0.17353229 0.48781356 0.33865415]\n",
      " [0.19175925 0.47671664 0.33152411]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['02', '023', '03', ..., 'япония', 'қазақстан', 'ҳукумат'],\n",
       "      dtype='<U29')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "rnd_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred2 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred2)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred2))\n",
    "print(rnd_clf.feature_importances_)\n",
    "print(rnd_clf.predict_proba(X_test))\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['RandomForestClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификатор Random Forest достиг примерно такого же уровня точности, что и без предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766666666666667\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18539103 0.81460897]\n",
      " [0.17543108 0.82456892]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1736363  0.8263637 ]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17087393 0.82912607]\n",
      " [0.19209775 0.80790225]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17535878 0.82464122]\n",
      " [0.19868684 0.80131316]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.17545027 0.82454973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.1837764  0.8162236 ]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17044786 0.82955214]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17486922 0.82513078]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17044786 0.82955214]\n",
      " [0.17213139 0.82786861]\n",
      " [0.18878441 0.81121559]\n",
      " [0.17543108 0.82456892]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17213139 0.82786861]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18878129 0.81121871]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17549168 0.82450832]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.1670427  0.8329573 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17240291 0.82759709]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544305 0.82455695]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18798928 0.81201072]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210732 0.82789268]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544545 0.82455455]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18382025 0.81617975]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18875962 0.81124038]\n",
      " [0.1736363  0.8263637 ]\n",
      " [0.32033514 0.67966486]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18382025 0.81617975]\n",
      " [0.17290299 0.82709701]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17087393 0.82912607]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.18382025 0.81617975]\n",
      " [0.16711212 0.83288788]\n",
      " [0.20322317 0.79677683]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17869693 0.82130307]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17549168 0.82450832]\n",
      " [0.17087393 0.82912607]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17709535 0.82290465]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.18710018 0.81289982]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18376683 0.81623317]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.18044066 0.81955934]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18986524 0.81013476]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544545 0.82455455]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16809661 0.83190339]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17295267 0.82704733]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18876203 0.81123797]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.213141   0.786859  ]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1812836  0.8187164 ]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.21205251 0.78794749]\n",
      " [0.20040958 0.79959042]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18047298 0.81952702]\n",
      " [0.17045027 0.82954973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19713922 0.80286078]\n",
      " [0.1887837  0.8112163 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.172854   0.827146  ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17045027 0.82954973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19215056 0.80784944]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19395936 0.80604064]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.20039766 0.79960234]\n",
      " [0.16984995 0.83015005]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17542157 0.82457843]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['000', '01', '04', ..., 'январе', 'январь', 'января'], dtype='<U32')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ext_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "ext_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(ExtraTreesClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred3 = grid_search_cv.predict(X_test)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred3))\n",
    "print(ext_clf.feature_importances_)\n",
    "print(ext_clf.predict_proba(X_test))\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['ExtraTreesClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый лучший результат показал здесь классификатор Extra Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем также выполнить задачу бинарной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = {'negative': -1, 'neutral': 1, 'positive': 1} \n",
    "data['y'] = data['sentiment'].map(lambda x: y[x])\n",
    "\n",
    "data_Y = data['y'].values\n",
    "data_X = data['text'].values\n",
    "\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = train_test_split(data_Y, data_X, test_size=0.3)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = dataY_train[:700], dataY_test[:300], dataX_train[:700], dataX_test[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766666666666667\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.16982263 0.83017737]\n",
      " [0.17840654 0.82159346]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1740095  0.8259905 ]\n",
      " [0.176361   0.823639  ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17113738 0.82886262]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16849734 0.83150266]\n",
      " [0.17155645 0.82844355]\n",
      " [0.16310269 0.83689731]\n",
      " [0.19066833 0.80933167]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16533161 0.83466839]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17161425 0.82838575]\n",
      " [0.16646324 0.83353676]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17693027 0.82306973]\n",
      " [0.17815876 0.82184124]\n",
      " [0.16722502 0.83277498]\n",
      " [0.17132267 0.82867733]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17155645 0.82844355]\n",
      " [0.17168651 0.82831349]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17146241 0.82853759]\n",
      " [0.16836419 0.83163581]\n",
      " [0.17143179 0.82856821]\n",
      " [0.18485992 0.81514008]\n",
      " [0.16995884 0.83004116]\n",
      " [0.19264592 0.80735408]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18388843 0.81611157]\n",
      " [0.16955907 0.83044093]\n",
      " [0.1714553  0.8285447 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18039607 0.81960393]\n",
      " [0.16784898 0.83215102]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17306361 0.82693639]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17147242 0.82852758]\n",
      " [0.20467499 0.79532501]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16979265 0.83020735]\n",
      " [0.17808526 0.82191474]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18399511 0.81600489]\n",
      " [0.18471585 0.81528415]\n",
      " [0.16849734 0.83150266]\n",
      " [0.17129061 0.82870939]\n",
      " [0.16849734 0.83150266]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17133627 0.82866373]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16578371 0.83421629]\n",
      " [0.1813209  0.8186791 ]\n",
      " [0.16159364 0.83840636]\n",
      " [0.17038808 0.82961192]\n",
      " [0.17745137 0.82254863]\n",
      " [0.17133627 0.82866373]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16943284 0.83056716]\n",
      " [0.19161744 0.80838256]\n",
      " [0.16800393 0.83199607]\n",
      " [0.17104439 0.82895561]\n",
      " [0.16808807 0.83191193]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16849734 0.83150266]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16722502 0.83277498]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17147242 0.82852758]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17502226 0.82497774]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16303321 0.83696679]\n",
      " [0.17086734 0.82913266]\n",
      " [0.17158666 0.82841334]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17977232 0.82022768]\n",
      " [0.17168651 0.82831349]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18134539 0.81865461]\n",
      " [0.16820732 0.83179268]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16914425 0.83085575]\n",
      " [0.16644331 0.83355669]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17150849 0.82849151]\n",
      " [0.19066833 0.80933167]\n",
      " [0.26577052 0.73422948]\n",
      " [0.1705213  0.8294787 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16578371 0.83421629]\n",
      " [0.16808807 0.83191193]\n",
      " [0.16495419 0.83504581]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17737247 0.82262753]\n",
      " [0.16159364 0.83840636]\n",
      " [0.17396046 0.82603954]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16825418 0.83174582]\n",
      " [0.17832652 0.82167348]\n",
      " [0.1740754  0.8259246 ]\n",
      " [0.17176264 0.82823736]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16611177 0.83388823]\n",
      " [0.16748235 0.83251765]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16427466 0.83572534]\n",
      " [0.17165342 0.82834658]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16689374 0.83310626]\n",
      " [0.19290335 0.80709665]\n",
      " [0.16820732 0.83179268]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16636961 0.83363039]\n",
      " [0.19849409 0.80150591]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.17124868 0.82875132]\n",
      " [0.16999498 0.83000502]\n",
      " [0.18381286 0.81618714]\n",
      " [0.16979265 0.83020735]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1714553  0.8285447 ]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17602628 0.82397372]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16943284 0.83056716]\n",
      " [0.17176264 0.82823736]\n",
      " [0.16533161 0.83466839]\n",
      " [0.16943284 0.83056716]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17735507 0.82264493]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17427492 0.82572508]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17414474 0.82585526]\n",
      " [0.21356293 0.78643707]\n",
      " [0.17133627 0.82866373]\n",
      " [0.17150849 0.82849151]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17959113 0.82040887]\n",
      " [0.17480801 0.82519199]\n",
      " [0.16533161 0.83466839]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17940524 0.82059476]\n",
      " [0.174918   0.825082  ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17155645 0.82844355]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16564975 0.83435025]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16577501 0.83422499]\n",
      " [0.16784898 0.83215102]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17808526 0.82191474]\n",
      " [0.16824063 0.83175937]\n",
      " [0.17158666 0.82841334]\n",
      " [0.1697466  0.8302534 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17520556 0.82479444]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16903837 0.83096163]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.1760413  0.8239587 ]\n",
      " [0.16564975 0.83435025]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17464176 0.82535824]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17961517 0.82038483]\n",
      " [0.17153974 0.82846026]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18248538 0.81751462]\n",
      " [0.1791779  0.8208221 ]\n",
      " [0.17372213 0.82627787]\n",
      " [0.17146004 0.82853996]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1922179  0.8077821 ]\n",
      " [0.1714553  0.8285447 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16722502 0.83277498]\n",
      " [0.18503859 0.81496141]\n",
      " [0.19698439 0.80301561]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17492842 0.82507158]\n",
      " [0.23411858 0.76588142]\n",
      " [0.18172252 0.81827748]\n",
      " [0.16619853 0.83380147]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.19865434 0.80134566]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16382256 0.83617744]\n",
      " [0.1685607  0.8314393 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.19328425 0.80671575]\n",
      " [0.16636961 0.83363039]\n",
      " [0.16578371 0.83421629]\n",
      " [0.16999498 0.83000502]\n",
      " [0.17144862 0.82855138]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16159364 0.83840636]\n",
      " [0.16808807 0.83191193]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16903837 0.83096163]\n",
      " [0.1756875  0.8243125 ]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18870578 0.81129422]\n",
      " [0.16310269 0.83689731]\n",
      " [0.1745735  0.8254265 ]\n",
      " [0.17055909 0.82944091]\n",
      " [0.16310269 0.83689731]\n",
      " [0.22989713 0.77010287]\n",
      " [0.17131852 0.82868148]\n",
      " [0.16310269 0.83689731]\n",
      " [0.18458058 0.81541942]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.16310269 0.83689731]\n",
      " [0.17155645 0.82844355]\n",
      " [0.17179664 0.82820336]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        37\n",
      "          1       0.88      1.00      0.93       263\n",
      "\n",
      "avg / total       0.77      0.88      0.82       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['01', '04', '047', '09', '10', '10369', '121', '13', '1306',\n",
       "       '1314', '1498', '156', '16', '167', '17', '19', '20', '2009',\n",
       "       '2015', '2016', '2017', '21', '210', '2305', '24', '243св', '25',\n",
       "       '259', '28', '288', '30', '325', '38', '41', '466', '467', '50',\n",
       "       '51', '53', '548', '57427', '58', '583', '592', '61', '6928',\n",
       "       '727', '728', '738', '99', 'aaa', 'asbn_dispute_case_120117',\n",
       "       'b270bn', 'bus', 'camonitor', 'carplay', 'ctrl', 'development',\n",
       "       'edinogo', 'enter', 'facebook', 'files', 'glavnaa', 'html', 'http',\n",
       "       'inform', 'iwf', 'kapital', 'kase', 'kaspi', 'kaznex', 'kb', 'kz',\n",
       "       'kселл', 'lse', 'matching', 'ne', 'web', 'xvii', 'абдижаббарова',\n",
       "       'абышевой', 'аварийную', 'автодорожной', 'автозаводов',\n",
       "       'автомобилей', 'автопрома', 'автопроме', 'автор', 'авторынок',\n",
       "       'автосборочные', 'агромашхолдинг', 'адиль', 'административной',\n",
       "       'акимом', 'актау', 'активности', 'активов', 'акций',\n",
       "       'акционерного', 'алатаумунайалтын', 'алии', 'алматинского',\n",
       "       'алматинской', 'алматы', 'алтаевой', 'аналитики', 'аналогичный',\n",
       "       'анарбай', 'антимонопольная', 'ао', 'арестован', 'арестованных',\n",
       "       'аресты', 'астана', 'атлетика', 'атлетики', 'атырау',\n",
       "       'атырауского', 'аурум', 'базе', 'базы', 'байкадамова', 'байтерек',\n",
       "       'банк', 'банка', 'банкротства', 'баракат', 'баста', 'бахтова',\n",
       "       'безопасного', 'бектемиров', 'беспокоят', 'бизнеса', 'бишимбаева',\n",
       "       'ближайших', 'блогер', 'болезненный', 'болел', 'будет', 'будут',\n",
       "       'бузгул', 'бумагу', 'бц', 'бывших', 'был', 'была', 'были', 'было',\n",
       "       'бюджета', 'бюрократии', 'важнее', 'валютной', 'ваххабитов',\n",
       "       'ващенко', 'вв', 'вглубь', 'ведомостей', 'ведут', 'величина',\n",
       "       'взаем', 'взятки', 'виде', 'визитам', 'вильнюсом', 'вину',\n",
       "       'вклады', 'во', 'водворен', 'возбудил', 'возбуждения', 'возврат',\n",
       "       'воздержался', 'возможным', 'возобновить', 'вопросам', 'вопросы',\n",
       "       'восемь', 'воскресение', 'восстановительный', 'восточный', 'вошли',\n",
       "       'впервые', 'время', 'врожденной', 'вряд', 'все', 'всего', 'всех',\n",
       "       'встречи', 'вторма', 'въезда', 'выгона', 'выданных', 'выдано',\n",
       "       'выделил', 'вызывали', 'вынес', 'выписки', 'выпущенной',\n",
       "       'выставляемое', 'высушенный', 'вышла', 'вэба', 'гаранин',\n",
       "       'геологоразведочной', 'главе', 'говорится', 'год', 'года', 'годом',\n",
       "       'города', 'городе', 'гранита', 'график', 'графика', 'греческого',\n",
       "       'грузовые', 'грузовых', 'грузооборота', 'данияр', 'данным',\n",
       "       'движения', 'девяти', 'дедолларизации', 'действие', 'действовала',\n",
       "       'декабрьской', 'декабря', 'день', 'депозите', 'депозитном',\n",
       "       'депозитным', 'депозитных', 'дефолте', 'дешевле', 'дивидендных',\n",
       "       'дилерами', 'директоров', 'дисконтных', 'для', 'дня', 'до',\n",
       "       'добавил', 'добавить', 'добывал', 'доверительном', 'договору',\n",
       "       'документ', 'документов', 'долгосрочные', 'должностьаким',\n",
       "       'должны', 'допросов', 'допросы', 'дорога', 'досаев', 'досрочного',\n",
       "       'досудебное', 'других', 'думаю', 'евгений', 'европы', 'его',\n",
       "       'енпф', 'ерденаев', 'еркебулан', 'если', 'еще', 'жалко',\n",
       "       'жангуразов', 'жарас', 'же', 'железной', 'женского', 'жертвы',\n",
       "       'жизнь', 'жилищное', 'жилых', 'жителей', 'жылыойском', 'за',\n",
       "       'заболеваний', 'закончился', 'закрепления', 'закрыла',\n",
       "       'замедляется', 'занят', 'западном', 'запрещена', 'запрос',\n",
       "       'зарплаты', 'заход', 'захотели', 'защите', 'заявили', 'заявку',\n",
       "       'зиадин', 'злоумышленники', 'злоупотреблении', 'значение',\n",
       "       'значимых', 'значительный', 'игорь', 'из', 'избран', 'известный',\n",
       "       'изменением', 'изменения', 'изолировать', 'изолятор', 'иин',\n",
       "       'ильина', 'имеет', 'импортно', 'инвестииям', 'инвестиции',\n",
       "       'индекса', 'инициирован', 'иностранной', 'инспектору', 'интер',\n",
       "       'информации', 'информер', 'инфраструктуры', 'ипотечная', 'искусно',\n",
       "       'исламбека', 'исполнять', 'истолковывая', 'источник', 'итоги',\n",
       "       'их', 'казахов', 'казахстан', 'казахстана', 'казахстане',\n",
       "       'казахстанских', 'казахстанской', 'казахстанцы', 'казенное',\n",
       "       'казинформ', 'кайрат', 'как', 'какие', 'калдаякову', 'карты',\n",
       "       'кассира', 'касымова', 'катание', 'классик', 'кнб', 'ко520',\n",
       "       'когда', 'кого', 'количеством', 'колл', 'коллегий', 'колодцам',\n",
       "       'колясочников', 'комитета', 'комментируя', 'компанией',\n",
       "       'комплекса', 'кондукторам', 'констракшн', 'контрольно',\n",
       "       'конференция', 'конца', 'конъюнктура', 'коротких', 'корреспондент',\n",
       "       'коррупции', 'которые', 'который', 'которых', 'крайне', 'красивый',\n",
       "       'кредиторами', 'кредитоспособности', 'критики', 'кровью',\n",
       "       'крысами', 'кск', 'ктж', 'куандык', 'куандыка', 'куата', 'курс',\n",
       "       'курсовую', 'кызылорду', 'кыргызский', 'лаврентьев', 'лейтенант',\n",
       "       'ли', 'либо', 'лидера', 'лидеров', 'лизинговая', 'личной',\n",
       "       'лоббирование', 'локальной', 'лучшим', 'льготных', 'людается',\n",
       "       'м3', 'магжан', 'малоэффективны', 'малым', 'мальчиков', 'мамин',\n",
       "       'материалам', 'материальных', 'машин', 'мая', 'мвк', 'между',\n",
       "       'межправсоглашения', 'менеджерам', 'меняться', 'мера',\n",
       "       'месторождения', 'месяца', 'месяцев', 'металлопродукции',\n",
       "       'металлургического', 'методов', 'мечты', 'миа', 'миллиона',\n",
       "       'милосердие', 'министерства', 'министерством', 'министр', 'минуты',\n",
       "       'мировой', 'мировую', 'млн', 'млрд', 'многомиллиардных',\n",
       "       'модельный', 'можете', 'можно', 'монополий', 'мошенничества',\n",
       "       'мощность', 'мы', 'на', 'наблюдательного', 'нагорнюк',\n",
       "       'надзорного', 'нажмите', 'названа', 'назвать', 'назначена',\n",
       "       'назначенное', 'найзагарин', 'накануне', 'накопления', 'налоговых',\n",
       "       'нарушало', 'нарушений', 'населения', 'научного', 'находящиеся',\n",
       "       'нацбанк', 'нацбанка', 'национальной', 'национальный',\n",
       "       'национальных', 'нацхолдинг', 'начале', 'начато', 'начиналась',\n",
       "       'наша', 'нашли', 'не', 'негативное', 'негативный', 'недавнее',\n",
       "       'недвижимостью', 'недолго', 'незаконно', 'нейтральную',\n",
       "       'неминуемо', 'необходимо', 'неоднократного', 'несмотря', 'нет',\n",
       "       'но', 'нового', 'новой', 'новом', 'ноябре', 'ноября', 'нурсултан',\n",
       "       'ныне', 'об', 'обвалилось', 'обвинение', 'обвиняемая', 'обвиняли',\n",
       "       'обвинялся', 'обвиняются', 'обеспечить', 'обещанные', 'обихода',\n",
       "       'областным', 'облигаций', 'обнародовал', 'оборудованы', 'образом',\n",
       "       'обратился', 'обращаться', 'объем', 'обязательное', 'один',\n",
       "       'одиночек', 'однако', 'одном', 'одобрил', 'одобрили', 'ожидающие',\n",
       "       'озвучивал', 'оказалась', 'оказано', 'оказывались', 'окончании',\n",
       "       'окончил', 'оксфорд', 'октября', 'олимпиаде', 'он', 'опасно',\n",
       "       'операции', 'описывается', 'определить', 'ориентирам',\n",
       "       'освободившиеся', 'освободителя', 'основного', 'особей',\n",
       "       'особенно', 'оставив', 'осуществленным', 'осуществляется',\n",
       "       'осуществлялась', 'осуществляя', 'от', 'отбеленного', 'отдавать',\n",
       "       'отдела', 'отдельным', 'отклонениями', 'открылась', 'отменяли',\n",
       "       'отметил', 'отмечается', 'отмечаются', 'относится', 'отравляет',\n",
       "       'отражает', 'отражается', 'отрицательного', 'отрицательной',\n",
       "       'отстранен', 'официальном', 'официальные', 'официальных', 'ошибке',\n",
       "       'ошибкой', 'памятнику', 'пандусы', 'парковки', 'парни',\n",
       "       'пассивного', 'педагоги', 'пенсионные', 'пенсионными', 'первичной',\n",
       "       'первичных', 'первые', 'перевозки', 'перевозок', 'перед',\n",
       "       'передает', 'перекрестного', 'пересмотр', 'перестрелки', 'писал',\n",
       "       'письма', 'пишу', 'платежей', 'по', 'поверило', 'повлияло',\n",
       "       'повреждено', 'повысилось', 'повысился', 'погрешности',\n",
       "       'подведены', 'подводит', 'подозрению', 'подписки', 'подписчикам',\n",
       "       'подтолкнули', 'подчерк', 'подъемник', 'поезда', 'пожизненно',\n",
       "       'позиции', 'позиция', 'пока', 'показателей', 'полных', 'положены',\n",
       "       'полотна', 'получения', 'поняла', 'пополнения', 'популярны',\n",
       "       'поручению', 'послания', 'пост', 'поставщика', 'пострадавших',\n",
       "       'посту', 'поступило', 'похожие', 'поясняется', 'правительства',\n",
       "       'правонарушения', 'правонарушениях', 'правоохранительных',\n",
       "       'праздник', 'превзошли', 'предложение', 'предоставить',\n",
       "       'предоставлено', 'предположительная', 'предположительно',\n",
       "       'предприятии', 'председатель', 'представил', 'представленном',\n",
       "       'предупреждали', 'предусматривается', 'президента', 'пресс',\n",
       "       'преступная', 'при', 'прибегают', 'прибудут', 'прибытию',\n",
       "       'приватизируемых', 'привел', 'привлечен', 'придется', 'прием',\n",
       "       'признались', 'признательные', 'принес', 'принято', 'принять',\n",
       "       'приостановлено', 'присвоение', 'пристальным', 'приуроченных',\n",
       "       'причиненного', 'причиной', 'пришли', 'прогноз', 'программе',\n",
       "       'продажи', 'продал', 'проданных', 'продержаться', 'продление',\n",
       "       'продукции', 'проект', 'прозрачными', 'произошло', 'пройдет',\n",
       "       'прокурору', 'прорыва', 'простоя', 'противодействию', 'процент',\n",
       "       'прочих', 'прошу', 'публикаций', 'пустили', 'пять', 'работ',\n",
       "       'работают', 'работе', 'работы', 'разбили', 'развитие', 'развитию',\n",
       "       'раздельно', 'размере', 'разместил', 'разработке', 'разъезжают',\n",
       "       'расположен', 'растянула', 'расчетам', 'реализовываются',\n",
       "       'регионе', 'регионы', 'резкий', 'рейтинг', 'рекламой', 'рекорд',\n",
       "       'религиозные', 'рельсов', 'репрессивным', 'республики', 'ресурсах',\n",
       "       'ресурсная', 'ресурсы', 'рецессия', 'речь', 'решением', 'решил',\n",
       "       'рисками', 'риски', 'рк', 'россии', 'россия', 'рубежа', 'рублей',\n",
       "       'садик', 'сайта', 'самолет', 'самолета', 'самым', 'самых',\n",
       "       'санкцию', 'санкциях', 'сбережения', 'своим', 'свою', 'сгорания',\n",
       "       'сегодня', 'сентрас', 'сергей', 'сидит', 'системах', 'системе',\n",
       "       'ситуацию', 'ситуация', 'скалодромы', 'сколково', 'скоростей',\n",
       "       'следственных', 'следующими', 'службу', 'службы', 'случае',\n",
       "       'смыслах', 'снизился', 'со', 'соблюдает', 'собственной',\n",
       "       'собственными', 'совершении', 'совершенным', 'совместно', 'совсем',\n",
       "       'согласно', 'содержит', 'создание', 'создать', 'сократилась',\n",
       "       'сомнительную', 'сообщает', 'сообщали', 'сообщалось', 'сообщение',\n",
       "       'сообщению', 'сообщил', 'сообщила', 'соответствует', 'составил',\n",
       "       'составила', 'составляет', 'составят', 'состоялось', 'состоящая',\n",
       "       'социально', 'социальных', 'спад', 'специальная', 'спид',\n",
       "       'спрашивается', 'среди', 'средств', 'средства', 'стабилизационная',\n",
       "       'стабилизационного', 'сталин', 'стартует', 'стастистику', 'статья',\n",
       "       'стороны', 'страны', 'страховых', 'стресс', 'стрижа',\n",
       "       'строительство', 'строящееся', 'субсидирование', 'суда', 'судом',\n",
       "       'сулейменов', 'существенно', 'существования', 'сходов', 'счет',\n",
       "       'съехала', 'так', 'такой', 'тарифов', 'твк', 'текстов', 'текстом',\n",
       "       'текущего', 'телефону', 'тем', 'температурный', 'тенге', 'тех',\n",
       "       'техника', 'технических', 'того', 'тоже', 'только', 'тому', 'тонн',\n",
       "       'тоо', 'топ', 'торги', 'торгового', 'транспорта', 'транспортном',\n",
       "       'третьей', 'третьем', 'тройка', 'тройку', 'туризма', 'тыс',\n",
       "       'убытках', 'уважением', 'уверен', 'уголовное', 'удержанию',\n",
       "       'удостоверению', 'уж', 'указанных', 'указано', 'улиц',\n",
       "       'умышленного', 'уникальный', 'употреблял', 'управления', 'уровень',\n",
       "       'уровни', 'усиления', 'условны', 'успешные', 'устанавливаемые',\n",
       "       'установки', 'участие', 'участников', 'учрежденной', 'уют',\n",
       "       'факту', 'финансовому', 'финансовые', 'финансовых', 'фондов',\n",
       "       'фрагмент', 'футболисту', 'хана', 'характерно', 'холдинг',\n",
       "       'холдинге', 'хранились', 'целлюлозно', 'целом', 'цементом',\n",
       "       'центр', 'центра', 'час', 'человек', 'через', 'четверг',\n",
       "       'чиновникам', 'чиновниками', 'числе', 'что', 'чужого',\n",
       "       'шардаринской', 'шестого', 'шимбуева', 'шкафах', 'экономических',\n",
       "       'экс', 'экспертов', 'электросетевой', 'электроснабжению',\n",
       "       'эльдара', 'эти', 'это', 'этого', 'этом', 'юко', 'юристов',\n",
       "       'являлись', 'январе', 'января', 'қаралды', 'әділет'], dtype='<U32')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "rnd_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred2 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred2)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred2))\n",
    "print(rnd_clf.feature_importances_)\n",
    "print(rnd_clf.predict_proba(X_test))\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred2))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['RandomForestClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат чуть-чуть выше, чем без предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766666666666667\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18539103 0.81460897]\n",
      " [0.17543108 0.82456892]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1736363  0.8263637 ]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17087393 0.82912607]\n",
      " [0.19209775 0.80790225]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17535878 0.82464122]\n",
      " [0.19868684 0.80131316]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.17545027 0.82454973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.1837764  0.8162236 ]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17044786 0.82955214]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17486922 0.82513078]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17044786 0.82955214]\n",
      " [0.17213139 0.82786861]\n",
      " [0.18878441 0.81121559]\n",
      " [0.17543108 0.82456892]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17213139 0.82786861]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18878129 0.81121871]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17549168 0.82450832]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.1670427  0.8329573 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17240291 0.82759709]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544305 0.82455695]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18798928 0.81201072]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210732 0.82789268]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544545 0.82455455]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18382025 0.81617975]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18875962 0.81124038]\n",
      " [0.1736363  0.8263637 ]\n",
      " [0.32033514 0.67966486]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18382025 0.81617975]\n",
      " [0.17290299 0.82709701]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17087393 0.82912607]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16535878 0.83464122]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16984995 0.83015005]\n",
      " [0.18382025 0.81617975]\n",
      " [0.16711212 0.83288788]\n",
      " [0.20322317 0.79677683]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17869693 0.82130307]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17549168 0.82450832]\n",
      " [0.17087393 0.82912607]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17709535 0.82290465]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.18710018 0.81289982]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18376683 0.81623317]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.18044066 0.81955934]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18986524 0.81013476]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17544545 0.82455455]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16809661 0.83190339]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17295267 0.82704733]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.17544305 0.82455695]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18876203 0.81123797]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.213141   0.786859  ]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686411  0.8313589 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1812836  0.8187164 ]\n",
      " [0.17546472 0.82453528]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.21205251 0.78794749]\n",
      " [0.20040958 0.79959042]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.18047298 0.81952702]\n",
      " [0.17045027 0.82954973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19713922 0.80286078]\n",
      " [0.1887837  0.8112163 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17210972 0.82789028]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.1686901  0.8313099 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.172854   0.827146  ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17132501 0.82867499]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17045027 0.82954973]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19215056 0.80784944]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.19395936 0.80604064]\n",
      " [0.1754335  0.8245665 ]\n",
      " [0.16711212 0.83288788]\n",
      " [0.20039766 0.79960234]\n",
      " [0.16984995 0.83015005]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.16711212 0.83288788]\n",
      " [0.17542157 0.82457843]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        37\n",
      "          1       0.88      1.00      0.93       263\n",
      "\n",
      "avg / total       0.77      0.88      0.82       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['000', '01', '03', ..., 'январе', 'января', 'ячеек'], dtype='<U32')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ext_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "ext_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(ExtraTreesClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred3 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred3)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred3))\n",
    "print(ext_clf.feature_importances_)\n",
    "print(ext_clf.predict_proba(X_test))\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred3))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['ExtraTreesClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой же результат, как и без предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        66\n",
      "          1       0.78      1.00      0.88       234\n",
      "\n",
      "avg / total       0.61      0.78      0.68       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['01', '1332', '2015', '2017', '21', '26', '60', '90', 'com',\n",
       "       'kase', 'kz', 'today', 'vedomosti', 'автомобиль', 'агентства',\n",
       "       'акишев', 'акции', 'акционеров', 'алматы', 'аналитика', 'анна',\n",
       "       'ао', 'аппарат', 'астана', 'атырау', 'байтерек', 'банк', 'банка',\n",
       "       'безопасности', 'билеты', 'бишимбаев', 'более', 'будут', 'бывшего',\n",
       "       'был', 'была', 'были', 'было', 'вагонов', 'ведомства', 'вернуться',\n",
       "       'вице', 'во', 'возможность', 'вот', 'время', 'все', 'всего',\n",
       "       'выручка', 'главы', 'говорит', 'года', 'году', 'города', 'граждан',\n",
       "       'данные', 'декабря', 'дел', 'детей', 'деятельности', 'директоров',\n",
       "       'для', 'должен', 'дом', 'другие', 'других', 'единиц', 'ему',\n",
       "       'енпф', 'ерденаева', 'же', 'за', 'завода', 'заседания',\n",
       "       'заявление', 'здравоохранения', 'или', 'имеет', 'иране',\n",
       "       'источник', 'итогам', 'казахстан', 'казахстана', 'казахстане',\n",
       "       'казахстанских', 'казахстанской', 'казинвестбанка', 'ккм',\n",
       "       'кодекса', 'конструкции', 'которые', 'который', 'которым', 'кск',\n",
       "       'ктж', 'лет', 'ликвидности', 'между', 'меньше', 'месяца',\n",
       "       'миллиардов', 'министра', 'млрд', 'многомиллиардных', 'мнэ',\n",
       "       'может', 'момент', 'мы', 'на', 'нажмите', 'нам', 'нацбанк',\n",
       "       'национальной', 'ндс', 'не', 'оао', 'объем', 'однако', 'отметил',\n",
       "       'отмечается', 'отношении', 'парка', 'пенсионные', 'пенсионных',\n",
       "       'первого', 'по', 'полицейские', 'полиции', 'порту', 'пош',\n",
       "       'правил', 'правительства', 'правительство', 'предпринимателей',\n",
       "       'председателем', 'президент', 'пресс', 'признались',\n",
       "       'прогнозирует', 'проекта', 'произошел', 'произошла', 'процента',\n",
       "       'развития', 'размере', 'расследование', 'ребенка', 'результате',\n",
       "       'рельсов', 'самрук', 'саранская', 'своих', 'связи', 'себя',\n",
       "       'сказал', 'скорой', 'словам', 'сообщает', 'сообщению',\n",
       "       'составляет', 'специальная', 'средств', 'средства', 'стал',\n",
       "       'стран', 'страны', 'строительство', 'суда', 'так', 'тенге',\n",
       "       'тенге1', 'того', 'том', 'тоо', 'трлн', 'трудового', 'тысяч',\n",
       "       'тэц', 'тяжелой', 'убытках', 'уголовного', 'ук', 'уровень',\n",
       "       'участие', 'февраля', 'фонд', 'центр', 'чем', 'что', 'чтобы',\n",
       "       'шахте', 'шаяхметова', 'экономики', 'энерго', 'это', 'январь'],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('LogisticRegression', LogisticRegression(penalty='l1'))]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'C': list(range(1, 5)), 'penalty': ['l1', 'l2']}\n",
    "grid_search_cv = GridSearchCV(LogisticRegression(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred4 = grid_search_cv.predict(X_test)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred4))\n",
    "\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred4))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['LogisticRegression'].coef_ != 0)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат стал лучше лишь немного.\n",
    "\n",
    "Лучшие результаты для бинарной классификации показали Random Forest и Extra Trees классификаторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя классификатор, который возвращает вероятности принадлежности к классу, рассмотрим несколько сообщений, в которых классификатор больше всего не уверен (то есть степень уверенности в одним из классов колеблется от 0.5 до 0.6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно судить по работе классификаторов Extra Trees и Random Forest, очень многие сообщения получили вероятность класса neutral = 0.5. Возможно, это зависит от уровня точности модели.\n",
    "\n",
    "Одно из таких сообщений - с индексом 10. Predict_proba классификатора Random Forest для одного из классов = 0.5076699. Также рассмотрим тексты, например, с индексами 27 (0.50432991) и 30 (0.50716492)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Долгожданный план, названный Министерством национальной экономики «Стратегией развития Казахстана до 2025 года», наконец-то увидел свет. Сколько копий было сломано вокруг него, сколько экспертов просиживало в приемной министра долгими часами, только бы внести свои коррективы в светлое будущее.\n",
      "Но будущее оказалось туманным, по крайней мере, именно такой вывод можно сделать, изучив документ. Все наполеоновские планы по типу «догнать и перегнать», видимо, Миннацэкономики оставило в прошлом и решило не сильно усложнять себе задачу, обозначив максимальным коридором ежегодного развития экономики скромные 3%. Об 11-12%, как это бывало в лучшие годы нашей жизни, уже никто и не говорит. Скромность, конечно, украшает г-на Бишимбаева, но явно не в вопросах экономического развития страны.\n",
      "Итак, что получилось в сухом остатке.\n",
      "В качестве ключевого индикатора Стратегии 2025 предлагается увеличение реального ВВП к 2025 году на 35%. Среднегодовые темпы роста экономики заявлены от 2,8% в 2015-2020 годах и до 3,3% в 2021-2025 годах. В стратегии очень много внимания уделено внешним факторам, таким как замедления темпов роста в Китае до 4-5%, потеря роли драйвера мировой экономики развивающимися экономики и угроза ловушки среднего дохода, о чем мы уже писали, говоря о том, что Казахстан погружается в ловушку недоразвития.\n",
      "Существует группа стран, достигших среднемирового ВВП на душу населения, но не проводивших вовремя политические реформы. Они попали в ловушку «недоразвития» и в дальнейшем не смогли удвоить объем ВВП. Например, Малайзия попала в эту ловушку, в том числе из-за сохранения конституционной монархии и авторитарного режима. Есть и группа стран, которым удалось вовремя провести политические реформы и войти в число развитых стран либо вплотную подойти к этому рубежу. В их числе Словения с ВВП по паритету покупательской способности (ППС) на душу населения $28 512 (политическая реформа в 1987-1991), Чехия – $27 347 (политическая реформа в 1989-1990), Эстония – $26 052 (политическая реформа в 1987-1991), Литва – $25 374 (политическая реформа в 1987-1991), Польша – $23 273 (политическая реформа в 1986-1990).\n",
      "Теперь эту угрозу открыто признает и Миннацэкономики. В свою очередь, экономисты министерства признают, что начался период завершения суперсырьевого цикла. Происходит трансформация мирового технологического уклада, в частности грядет деоффшаризация промышленного производства за счет повышения экологичности и снижения трудозатрат, стоит ждать повсеместного закрытия традиционных энергоемких производств в развитых странах. В Министерстве национальной экономики полагают, что свое влияние на развитие Казахстана, несомненно будет оказывать «возрастание угроз глобальной безопасности» и переформатирование глобальных процессов, в частности переход от межстрановой конкуренции к конкуренции между региональными интеграционными структурами, рост числа соглашений о свободной торговле. Дает министерство ответ и на то, как эти вызовы повлияют на Казахстан. Произойдет сжатие рынков сбыта для казахстанского сырья, составляющего более 70% от объема экспорта. Будет повсеместный спад в экономиках основных торговых партнеров Казахстана, существует угроза дестабилизации казахстанской финансовой системы на фоне валютных войн и риски втягивания Казахстана в региональные экономические противостояния и выпадение из орбиты крупных региональных соглашений.\n",
      "Также в исходном стратегическом плане МНЭ до 2025 года утверждается, что все импортированные угрозы усиливают риски сохранения низких темпов роста экономики Казахстана в долгосрочном периоде и социальной напряженности.\n",
      "Негативное внешнее влияние усугубляется кучей внутренних проблем Казахстана, таких как чрезмерная доля присутствия государства в экономике, ограничение конкуренции и проблемы МСБ, высокая зависимость от экспорта сырьевых товаров, которые составляют 71,6% от общего числа. Нестабильно и в банковском секторе, существует высокий уровень долларизации и ограниченный доступ к тенговой ликвидности. Угрозу представляет неравномерное социально-экономическое развитие регионов, при этом рост численности городского населения не сопровождается созданием качественных рабочих мест и социальной инфраструктуры.\n",
      "Понимая все эти болячки современного Казахстана ведомство Куандыка Бишимбаева, между тем, предлагает до боли знакомый стандартный набор мер, который не выстреливал и в прошлые разы и не факт, что удастся что-то сделать сейчас. Но звучит красиво. Так, МНЭ предлагает радикальное и форсированное снижение участия государства в экономике, конкретные механизмы достижения этой светлой цели не приводятся. Так, Миннацэкономике анонсирует полный переход к бюджетной политике, ориентированной на результат (не понятно, на что была ориентация до этого), произойдет, по уверенности МНЭ кардинальный пересмотр бизнес-процессов в сфере госслужбы, обеспечение верховенства права и смещение акцентов на проактивную экономическую дипломатию. Конечно, г-н Бишимбаев довольно молодой человек, но все же уже не мальчик и трудно понять его святую веру в сказки. «О, святая простота», - благо это за многие лета до этого было сказано не о министре нацэкономики.\n",
      "МНЭ предлагает осуществить 7 национальных достижений и уверяет, что к 2025 году будут созданы новые драйверы роста экономики, обеспечено верховенство закона, Казахстан станет страной равных возможностей, будет создан единый интегрированный рынок, значительно расширится доля среднего класса, будет выстроено равное партнерство между государством, бизнесом и гражданами, а Казахстан сохранит лидирующие позиции в ЦА и укрепит дружественные связи со всеми странами региона. И все эти «ништяки» будут происходить на фоне 2-3% роста экономики ежегодно.\n",
      "При этом в более ранней Концепции перехода Республики Казахстан к устойчивому развитию на 2007-2024 годы отмечалось, что к 2024 году страна достигнет следующих результатов:\n",
      "В условиях новой Стратегии МНЭ все ранее озвученные планы развития, в том числе по вхождению в ТОП-30 развитых стран мира перечеркиваются исходя из крайне неамбициозной постановки главной цели. Конечно, за фасадом общих лозунгов про обеспечение верховенства права и роста среднего класса можно многое замаскировать, но основной индикатор – темпы экономического роста, которые заявляет МНЭ, кажутся абсолютно несоразмерными с масштабами тех задач, которые ранее были поставлены государством.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataX_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Алматы. 6 января. КазТАГ - Ксения Бондал. Основанием для возбуждения уголовного дела по сделке Единого накопительного пенсионного фонда (ЕНПФ) стало заявление Национального банка РК, сообщил начальник управления по защите прав потребителей финансовых услуг и внешних коммуникаций Нацбанка Александр Терентьев. \n",
      "\n",
      "«Ранее мы эту информацию не озвучивали, за это мы получили всякие кривотолки и осуждения. Основанием для возбуждения уголовного дела стало заявление Нацбанка. Нам эта сделка (по покупке облигаций со стороны ЕНПФ - КазТАГ) показалась сомнительной, поэтому Нацбанк обратился 25 ноября 2016 года с письмом в правоохранительные органы. Это пока все, что я могу вам сообщить. Следствие идет, проверка проводится, думаю, в ближайшее время вы информацию про данному уголовному делу получите», - сказал А.Терентьев на пресс-конференции в пятницу. \n",
      "\n",
      "Как сообщалось, правоохранительными органами Казахстана с 21 декабря ведется проверка деятельности АО «ЕНПФ». Проверка осуществляется по операциям, совершенным ЕНПФ в отношении инвестирования собственных активов. Собственные активы ЕНПФ формируются за счет его капитала и результатов хозяйственной деятельности. \n",
      "\n",
      "Как стало известно, ЕНПФ приобрел облигации ТОО «Бозгул Аурум» на сумму Т5 млрд за счет собственных средств. Сделка прошла на организованном рынке в торговой системе Казахстанской фондовой биржи. В результате этой покупки ДКНБ Алматы возбудил уголовное дело.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataX_test[27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Авиакомпания SCAT подводит статистику по своим направлениям, согласно которой Грузия заняла одно из лидирующих мест. Открытый впервые в истории взаимоотношений между Республикой Казахстан и Республикой Грузия рейс Актау — Батуми показал самый стремительный рост пассажиропотока в летнем сезоне со средней загрузкой 85 процентов. \n",
      "\n",
      "Исторический рейс Актау — Тбилиси, выполняемый авиакомпанией на протяжении 18 лет, уже за десять месяцев 2016 года показал 12-процентное увеличение пассажиропотока по сравнению с годовым показателем 2015 года, несмотря на открытие одного из самых популярных сезонных рейсов Актау — Батуми и других конкурирующих направлений. \n",
      "\n",
      "В связи с этим авиакомпания приняла решение о запуске акции в преддверии зимнего горнолыжного сезона в Грузии. Все пассажиры, приобретая билеты на любое направление авиакомпании SCAT в период с 21 ноября по 4 декабря, могут выиграть выходные на двоих в Тбилиси с предоставлением проживания и насыщенной культурной программой. Дополнительными призами объявлены перелеты в обе стороны на любой международный рейс и любой рейс авиакомпании SCAT по Казахстану. Авиакомпания SCAT прогнозирует перевезти более 25 000 человек в Грузию по результатам 2016 года. Более подробную информацию о рейсах и условиях участия в акции возможно узнать на сайте scat.kz. \n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataX_test[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какими же могут быть причины неуверенности классификатора?\n",
    "\n",
    "При подробном рассмотрении можно слелать вывод, что на это могут влиять такие факторы, как:\n",
    "1) недостаточное количество в тексте слов, которых классификатор считает важными для определения класса\n",
    "2) непосредственно длина текста, которая и сокращает вероятность попадания в него важных характеристик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Несовершенность модели.\n",
    "Рассмотрим, например, разницу между словами, определенными как важные, логистической регрессией и классификатором Rantom forest. Многие из этих слов в двух разных моделях совпадают. Но это более общие слова, которые могли бы встретиться в текстах разной эмоциональной окрашенности. Например, Казахстан, Астана, год, назнание месяцев и валют. \n",
    "\n",
    "Однако, также среди общей тематики слов встречались те темы, которые уже, возможно, могли бы повлиять на определение тональности. Это слова из тематического поля \"криминал\":уголовный, заержан, злоупотребление, запрещено. Также слова с положительной семантикой: уют, развитие. \n",
    "\n",
    "В целом классификатор Rantom forest предложил более обширный список значимых слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Три класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#загружаем дата-сет\n",
    "data = pd.read_json('train.json', encoding = 'utf-8')\n",
    "data.head(10)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#присваиваем классам числовое значение\n",
    "y = {'negative': -1, 'neutral': 0, 'positive': 1} \n",
    "data['y'] = data['sentiment'].map(lambda x: y[x])\n",
    "\n",
    "#делим данные на x и y, в x будут тексты, а в у - класс\n",
    "data_Y = data['y'].values\n",
    "data_X = data['text'].values\n",
    "\n",
    "#делим данные на тренировочную и тестовую выборку, тестовая выборка - 30% (здесь взята только часть примеров, а не весь корпус - это связано с мощностью компьютера)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = train_test_split(data_Y, data_X, test_size=0.3, shuffle=True)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = dataY_train[:700], dataY_test[:300], dataX_train[:700], dataX_test[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(dataX_train)\n",
    "X_train = vectorizer.transform(dataX_train)\n",
    "X_test = vectorizer.transform(dataX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 47827)\t0.04592616781897563\n",
      "  (0, 47394)\t0.04747150142653724\n",
      "  (0, 47063)\t0.06579911699316304\n",
      "  (0, 45974)\t0.0646904895561301\n",
      "  (0, 45471)\t0.042086765306051044\n",
      "  (0, 45003)\t0.0757628274234735\n",
      "  (0, 44997)\t0.15556164982217482\n",
      "  (0, 44994)\t0.06128096838561277\n",
      "  (0, 44818)\t0.05060330304823705\n",
      "  (0, 44498)\t0.06888695875843028\n",
      "  (0, 44497)\t0.06037042101624428\n",
      "  (0, 44002)\t0.05626891198805237\n",
      "  (0, 43128)\t0.07078097220831826\n",
      "  (0, 42561)\t0.03806637658314542\n",
      "  (0, 42415)\t0.1235584506923133\n",
      "  (0, 42281)\t0.04602432873841278\n",
      "  (0, 42278)\t0.038651571312605326\n",
      "  (0, 42050)\t0.08427936516565951\n",
      "  (0, 41996)\t0.019875242144220567\n",
      "  (0, 41794)\t0.035267648551449794\n",
      "  (0, 41398)\t0.05185388327405827\n",
      "  (0, 41389)\t0.06450457691090924\n",
      "  (0, 40761)\t0.10012090530468541\n",
      "  (0, 40146)\t0.07420982018179162\n",
      "  (0, 40114)\t0.07929750995050427\n",
      "  :\t:\n",
      "  (0, 6789)\t0.06226443446613227\n",
      "  (0, 6572)\t0.09556515085654306\n",
      "  (0, 6567)\t0.07193988130205384\n",
      "  (0, 6540)\t0.026922956502342995\n",
      "  (0, 6392)\t0.027944939124643044\n",
      "  (0, 4800)\t0.03974793344100375\n",
      "  (0, 4796)\t0.12074084203248855\n",
      "  (0, 4133)\t0.02969354535361789\n",
      "  (0, 3342)\t0.05538856580108905\n",
      "  (0, 3336)\t0.1107771316021781\n",
      "  (0, 3268)\t0.07929750995050427\n",
      "  (0, 1385)\t0.05481698521902335\n",
      "  (0, 1271)\t0.05481698521902335\n",
      "  (0, 1229)\t0.05538856580108905\n",
      "  (0, 1188)\t0.05185388327405827\n",
      "  (0, 1179)\t0.05185388327405827\n",
      "  (0, 1088)\t0.05142272441201922\n",
      "  (0, 766)\t0.042489646211382\n",
      "  (0, 717)\t0.07078097220831826\n",
      "  (0, 637)\t0.04059563276149401\n",
      "  (0, 634)\t0.04497801460901505\n",
      "  (0, 629)\t0.02128590138269077\n",
      "  (0, 365)\t0.06579911699316304\n",
      "  (0, 259)\t0.033669716097450085\n",
      "  (0, 215)\t0.03549731443013282\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "linsvc_clf = LinearSVC(C=5, loss=\"hinge\", penalty = 'l2', multi_class = 'ovr')\n",
    "\n",
    "#применим gridsearch для поиска оптимальных значений гиперпараметров\n",
    "param_grid = {'C': list(range(1, 5)), 'loss': ['hinge', 'squared_hinge']}\n",
    "grid_search_cv = GridSearchCV(LinearSVC(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred1 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred1)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5633333333333334\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.16159957 0.49351333 0.3448871 ]\n",
      " [0.16829744 0.49050427 0.34119829]\n",
      " [0.15587527 0.48078298 0.36334175]\n",
      " [0.15880474 0.49031772 0.35087754]\n",
      " [0.16252933 0.4872002  0.35027048]\n",
      " [0.15674013 0.48736882 0.35589105]\n",
      " [0.15674095 0.46702465 0.3762344 ]\n",
      " [0.17666683 0.48833367 0.3349995 ]\n",
      " [0.16202447 0.47396703 0.36400849]\n",
      " [0.15371823 0.48339899 0.36288278]\n",
      " [0.17604258 0.4896253  0.33433212]\n",
      " [0.16006547 0.46553381 0.37440073]\n",
      " [0.15953028 0.48782164 0.35264808]\n",
      " [0.16277234 0.47100352 0.36622414]\n",
      " [0.15710314 0.47554664 0.36735022]\n",
      " [0.16362416 0.49035706 0.34601879]\n",
      " [0.15501456 0.47199663 0.37298881]\n",
      " [0.15319429 0.46807136 0.37873435]\n",
      " [0.27111319 0.44381088 0.28507593]\n",
      " [0.16346861 0.49277022 0.34376117]\n",
      " [0.18696586 0.47118567 0.34184847]\n",
      " [0.15973218 0.48251131 0.35775651]\n",
      " [0.15711181 0.47925272 0.36363547]\n",
      " [0.17726725 0.49455407 0.32817868]\n",
      " [0.15752609 0.4818869  0.36058701]\n",
      " [0.16871097 0.47427148 0.35701755]\n",
      " [0.17475922 0.47126403 0.35397675]\n",
      " [0.16046924 0.47579207 0.36373869]\n",
      " [0.15364003 0.48675849 0.35960147]\n",
      " [0.16170873 0.49618343 0.34210784]\n",
      " [0.15799391 0.48621718 0.35578891]\n",
      " [0.15613342 0.49613483 0.34773175]\n",
      " [0.15497232 0.5043196  0.34070808]\n",
      " [0.23138415 0.47746817 0.29114769]\n",
      " [0.15826543 0.48482411 0.35691047]\n",
      " [0.17842231 0.48529806 0.33627962]\n",
      " [0.15505675 0.4722729  0.37267035]\n",
      " [0.16050791 0.48031055 0.35918154]\n",
      " [0.18545024 0.48239762 0.33215214]\n",
      " [0.15637451 0.47824096 0.36538453]\n",
      " [0.1760346  0.4712491  0.3527163 ]\n",
      " [0.1831219  0.49042265 0.32645545]\n",
      " [0.167514   0.50234963 0.33013637]\n",
      " [0.17134408 0.47984851 0.34880741]\n",
      " [0.1685464  0.4635236  0.36793   ]\n",
      " [0.16115011 0.49195258 0.34689731]\n",
      " [0.19791376 0.48119848 0.32088776]\n",
      " [0.15267622 0.46396185 0.38336193]\n",
      " [0.15973841 0.48555355 0.35470804]\n",
      " [0.157201   0.48517857 0.35762043]\n",
      " [0.16223168 0.49029995 0.34746837]\n",
      " [0.17565679 0.49531883 0.32902438]\n",
      " [0.19812057 0.46428205 0.33759738]\n",
      " [0.15752943 0.48760907 0.3548615 ]\n",
      " [0.1796661  0.47701496 0.34331893]\n",
      " [0.17185647 0.4805835  0.34756003]\n",
      " [0.22235404 0.45450302 0.32314294]\n",
      " [0.15549945 0.48595845 0.35854209]\n",
      " [0.15139015 0.49805401 0.35055583]\n",
      " [0.18444122 0.46680693 0.34875186]\n",
      " [0.16539731 0.47635727 0.35824542]\n",
      " [0.16422866 0.49005405 0.34571728]\n",
      " [0.15958679 0.48193413 0.35847908]\n",
      " [0.18780298 0.48290495 0.32929207]\n",
      " [0.16300884 0.47843978 0.35855137]\n",
      " [0.16007689 0.48322598 0.35669713]\n",
      " [0.15934439 0.49608725 0.34456836]\n",
      " [0.16354595 0.49109622 0.34535783]\n",
      " [0.16579696 0.48351587 0.35068717]\n",
      " [0.15899742 0.4918605  0.34914208]\n",
      " [0.16835589 0.49167069 0.33997343]\n",
      " [0.15749101 0.49564016 0.34686883]\n",
      " [0.16998866 0.48266469 0.34734664]\n",
      " [0.18016171 0.48385832 0.33597997]\n",
      " [0.25837282 0.4415206  0.30010658]\n",
      " [0.15249354 0.50368485 0.34382161]\n",
      " [0.23138415 0.47746817 0.29114769]\n",
      " [0.15421168 0.47033135 0.37545697]\n",
      " [0.14883835 0.47866249 0.37249916]\n",
      " [0.20525072 0.47946949 0.31527979]\n",
      " [0.16136783 0.49965829 0.33897388]\n",
      " [0.16393615 0.48521911 0.35084474]\n",
      " [0.16167259 0.48453802 0.35378939]\n",
      " [0.16387537 0.48653557 0.34958907]\n",
      " [0.15252284 0.4714721  0.37600506]\n",
      " [0.17147728 0.48378943 0.3447333 ]\n",
      " [0.15536451 0.48656295 0.35807254]\n",
      " [0.1567873  0.49659775 0.34661495]\n",
      " [0.1673981  0.48636001 0.34624189]\n",
      " [0.1561165  0.491707   0.3521765 ]\n",
      " [0.16027405 0.52011229 0.31961366]\n",
      " [0.16260341 0.48667917 0.35071741]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.15811965 0.49464336 0.34723699]\n",
      " [0.17386282 0.48355235 0.34258483]\n",
      " [0.1525354  0.49669384 0.35077076]\n",
      " [0.14827501 0.46572996 0.38599503]\n",
      " [0.1579538  0.46835673 0.37368947]\n",
      " [0.16864775 0.47912665 0.3522256 ]\n",
      " [0.15501456 0.47199663 0.37298881]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.15612178 0.48028864 0.36358959]\n",
      " [0.15661924 0.50269714 0.34068361]\n",
      " [0.16896773 0.48211221 0.34892006]\n",
      " [0.15890996 0.47058018 0.37050985]\n",
      " [0.15820478 0.46353579 0.37825943]\n",
      " [0.16157494 0.48247912 0.35594594]\n",
      " [0.16300987 0.47431095 0.36267918]\n",
      " [0.1787117  0.49214945 0.32913885]\n",
      " [0.16814097 0.48757598 0.34428305]\n",
      " [0.15191649 0.46543528 0.38264823]\n",
      " [0.16545511 0.49163957 0.34290532]\n",
      " [0.1701274  0.48558328 0.34428932]\n",
      " [0.15988214 0.49733124 0.34278663]\n",
      " [0.15895722 0.49298445 0.34805833]\n",
      " [0.15929736 0.47915161 0.36155103]\n",
      " [0.16135292 0.49626619 0.34238089]\n",
      " [0.15488343 0.47777716 0.3673394 ]\n",
      " [0.18447862 0.46484434 0.35067704]\n",
      " [0.1574774  0.48173835 0.36078425]\n",
      " [0.16017245 0.47904041 0.36078714]\n",
      " [0.17494074 0.49340168 0.33165759]\n",
      " [0.18905024 0.49045137 0.32049839]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.17929774 0.48607444 0.33462782]\n",
      " [0.15678794 0.47708569 0.36612637]\n",
      " [0.15921929 0.4973376  0.3434431 ]\n",
      " [0.17696228 0.48176159 0.34127613]\n",
      " [0.16445529 0.47948148 0.35606323]\n",
      " [0.16865882 0.47957328 0.35176789]\n",
      " [0.16013791 0.49135765 0.34850444]\n",
      " [0.16143981 0.49378486 0.34477533]\n",
      " [0.15956044 0.4871465  0.35329305]\n",
      " [0.15877061 0.48055798 0.3606714 ]\n",
      " [0.16021767 0.49594938 0.34383295]\n",
      " [0.15609404 0.47255957 0.3713464 ]\n",
      " [0.18087402 0.48541012 0.33371586]\n",
      " [0.19659417 0.48127784 0.322128  ]\n",
      " [0.16137174 0.48246687 0.35616139]\n",
      " [0.14683041 0.45493641 0.39823318]\n",
      " [0.15769346 0.4824652  0.35984134]\n",
      " [0.17705806 0.47270395 0.35023799]\n",
      " [0.16156999 0.46874174 0.36968827]\n",
      " [0.18088118 0.48571966 0.33339916]\n",
      " [0.16608269 0.48777677 0.34614055]\n",
      " [0.16790658 0.48491595 0.34717747]\n",
      " [0.17084928 0.48907104 0.34007968]\n",
      " [0.18049356 0.47394743 0.34555901]\n",
      " [0.17195072 0.48618198 0.34186729]\n",
      " [0.15621879 0.51188974 0.33189148]\n",
      " [0.15618225 0.51425455 0.32956321]\n",
      " [0.16765737 0.48376733 0.34857529]\n",
      " [0.15972765 0.46029836 0.37997399]\n",
      " [0.1607726  0.49158707 0.34764033]\n",
      " [0.17939723 0.46912027 0.3514825 ]\n",
      " [0.15802523 0.48179022 0.36018455]\n",
      " [0.1529969  0.46936249 0.37764061]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.17046285 0.48509075 0.34444641]\n",
      " [0.18080475 0.47778169 0.34141356]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.15852036 0.4740962  0.36738344]\n",
      " [0.16572124 0.48332721 0.35095155]\n",
      " [0.17326754 0.47951587 0.34721658]\n",
      " [0.2710942  0.44248791 0.28641789]\n",
      " [0.18229699 0.50713431 0.3105687 ]\n",
      " [0.15160977 0.49251409 0.35587614]\n",
      " [0.1653689  0.50705008 0.32758102]\n",
      " [0.18089032 0.49373279 0.32537689]\n",
      " [0.17661911 0.4783599  0.345021  ]\n",
      " [0.30881453 0.41702411 0.27416136]\n",
      " [0.17961453 0.51255671 0.30782876]\n",
      " [0.15866352 0.48141035 0.35992613]\n",
      " [0.15698841 0.4782074  0.3648042 ]\n",
      " [0.16277431 0.47881687 0.35840882]\n",
      " [0.16248644 0.48445053 0.35306303]\n",
      " [0.14727168 0.50581643 0.34691189]\n",
      " [0.18582015 0.4824102  0.33176965]\n",
      " [0.17800059 0.4783547  0.34364471]\n",
      " [0.1601449  0.50132545 0.33852965]\n",
      " [0.15232049 0.45231176 0.39536775]\n",
      " [0.163371   0.49381212 0.34281687]\n",
      " [0.15333493 0.49017839 0.35648668]\n",
      " [0.15246116 0.51026666 0.33727217]\n",
      " [0.16029213 0.48932358 0.35038428]\n",
      " [0.15862465 0.49527364 0.34610171]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.15653146 0.49527349 0.34819505]\n",
      " [0.15666916 0.4795353  0.36379555]\n",
      " [0.1733295  0.48549387 0.34117663]\n",
      " [0.21831659 0.47064729 0.31103612]\n",
      " [0.15425402 0.48484968 0.36089631]\n",
      " [0.16704255 0.49637783 0.33657963]\n",
      " [0.17048738 0.47751579 0.35199682]\n",
      " [0.16879036 0.49246322 0.33874642]\n",
      " [0.17506195 0.50656555 0.3183725 ]\n",
      " [0.16100967 0.48312315 0.35586717]\n",
      " [0.15780401 0.49137219 0.35082381]\n",
      " [0.17027364 0.47876373 0.35096263]\n",
      " [0.16447621 0.48927381 0.34624998]\n",
      " [0.15768026 0.48886152 0.35345821]\n",
      " [0.16064863 0.50202169 0.33732968]\n",
      " [0.16067842 0.4881383  0.35118328]\n",
      " [0.18728662 0.50971573 0.30299765]\n",
      " [0.15501456 0.47199663 0.37298881]\n",
      " [0.15266528 0.47827895 0.36905576]\n",
      " [0.17612221 0.48746987 0.33640792]\n",
      " [0.17667215 0.45876378 0.36456407]\n",
      " [0.19657498 0.4589151  0.34450993]\n",
      " [0.16163758 0.48819386 0.35016856]\n",
      " [0.17922959 0.46990807 0.35086235]\n",
      " [0.18078666 0.49000451 0.32920883]\n",
      " [0.15339299 0.47136739 0.37523962]\n",
      " [0.23854653 0.44891543 0.31253804]\n",
      " [0.16071629 0.48423122 0.35505248]\n",
      " [0.16491214 0.48886824 0.34621962]\n",
      " [0.16193034 0.48518147 0.35288818]\n",
      " [0.16129969 0.48417757 0.35452274]\n",
      " [0.16046924 0.47579207 0.36373869]\n",
      " [0.19096185 0.46566356 0.34337459]\n",
      " [0.1472585  0.45247265 0.40026885]\n",
      " [0.16429849 0.49377038 0.34193113]\n",
      " [0.16206988 0.49047325 0.34745687]\n",
      " [0.15957069 0.50308703 0.33734227]\n",
      " [0.15016146 0.47833123 0.37150731]\n",
      " [0.16377195 0.47013878 0.36608927]\n",
      " [0.160838   0.49472571 0.34443629]\n",
      " [0.15340181 0.49292333 0.35367485]\n",
      " [0.1533505  0.50486969 0.34177981]\n",
      " [0.17676105 0.48972524 0.3335137 ]\n",
      " [0.17181812 0.4878611  0.34032079]\n",
      " [0.16399457 0.47184653 0.36415889]\n",
      " [0.15837915 0.48651074 0.35511011]\n",
      " [0.15480274 0.48658482 0.35861244]\n",
      " [0.15723543 0.46631602 0.37644854]\n",
      " [0.17380508 0.48673104 0.33946388]\n",
      " [0.16413606 0.47419181 0.36167212]\n",
      " [0.1752895  0.4873957  0.3373148 ]\n",
      " [0.15811207 0.47871303 0.3631749 ]\n",
      " [0.17917669 0.48197103 0.33885228]\n",
      " [0.19345228 0.48100666 0.32554106]\n",
      " [0.19140576 0.47366375 0.33493049]\n",
      " [0.164081   0.49627372 0.33964527]\n",
      " [0.15511552 0.49032096 0.35456352]\n",
      " [0.15954136 0.49270763 0.34775101]\n",
      " [0.17782137 0.49742561 0.32475301]\n",
      " [0.15907975 0.48151698 0.35940327]\n",
      " [0.16105717 0.47374959 0.36519324]\n",
      " [0.16120037 0.48095182 0.35784781]\n",
      " [0.16495462 0.4955646  0.33948078]\n",
      " [0.15909263 0.4890122  0.35189516]\n",
      " [0.19084593 0.48593658 0.3232175 ]\n",
      " [0.15528156 0.49267096 0.35204748]\n",
      " [0.1964512  0.4859009  0.3176479 ]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.15462692 0.48381614 0.36155693]\n",
      " [0.16180335 0.48268358 0.35551307]\n",
      " [0.16427189 0.47748819 0.35823992]\n",
      " [0.15441892 0.50723714 0.33834395]\n",
      " [0.1937726  0.48794627 0.31828113]\n",
      " [0.15966547 0.48480023 0.3555343 ]\n",
      " [0.15870297 0.49763047 0.34366656]\n",
      " [0.15553224 0.46172534 0.38274242]\n",
      " [0.16934564 0.48342422 0.34723013]\n",
      " [0.1506941  0.48689403 0.36241187]\n",
      " [0.15600093 0.49831925 0.34567982]\n",
      " [0.18213307 0.48036146 0.33750547]\n",
      " [0.1475075  0.45434843 0.39814406]\n",
      " [0.16558242 0.4799113  0.35450628]\n",
      " [0.1564998  0.48051816 0.36298204]\n",
      " [0.15358693 0.47890015 0.36751292]\n",
      " [0.1541781  0.48859318 0.35722872]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.15991838 0.50492574 0.33515588]\n",
      " [0.17042816 0.49235887 0.33721296]\n",
      " [0.16408536 0.46304558 0.37286906]\n",
      " [0.16000583 0.49292583 0.34706834]\n",
      " [0.15027456 0.48226978 0.36745566]\n",
      " [0.15655385 0.46130582 0.38214033]\n",
      " [0.17074743 0.4828387  0.34641387]\n",
      " [0.16036333 0.48140154 0.35823513]\n",
      " [0.15813843 0.48702383 0.35483774]\n",
      " [0.15954679 0.48801827 0.35243494]\n",
      " [0.1554046  0.47448236 0.37011304]\n",
      " [0.15209615 0.4802082  0.36769565]\n",
      " [0.17999534 0.48214516 0.3378595 ]\n",
      " [0.17181835 0.48593218 0.34224947]\n",
      " [0.16082823 0.47963895 0.35953282]\n",
      " [0.20766181 0.48086048 0.31147771]\n",
      " [0.16022377 0.48690186 0.35287437]\n",
      " [0.19137627 0.48059289 0.32803084]\n",
      " [0.18102019 0.49863006 0.32034975]\n",
      " [0.16338967 0.48876173 0.3478486 ]\n",
      " [0.16134817 0.48837206 0.35027978]\n",
      " [0.15667376 0.48715738 0.35616885]\n",
      " [0.14927086 0.45766622 0.39306292]\n",
      " [0.15725915 0.47992506 0.36281579]\n",
      " [0.15571555 0.47752924 0.36675521]\n",
      " [0.15962243 0.48514868 0.35522889]\n",
      " [0.16846011 0.52142529 0.3101146 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['000', '000м3', '003', ..., 'қатновни', 'үйі', 'әділет'],\n",
       "      dtype='<U80')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "rnd_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred2 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred2)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred2))\n",
    "print(rnd_clf.feature_importances_)\n",
    "print(rnd_clf.predict_proba(X_test))\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['RandomForestClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5533333333333333\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.1627648  0.49825986 0.33897534]\n",
      " [0.16437397 0.47574178 0.35988426]\n",
      " [0.1640533  0.48326445 0.35268226]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16576831 0.48630032 0.34793137]\n",
      " [0.16750799 0.48123964 0.35125238]\n",
      " [0.16792081 0.48439208 0.34768711]\n",
      " [0.18039934 0.4879355  0.33166516]\n",
      " [0.16321491 0.47779352 0.35899157]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.17885004 0.48041063 0.34073933]\n",
      " [0.16312603 0.47134621 0.36552777]\n",
      " [0.16761418 0.47811545 0.35427037]\n",
      " [0.16175816 0.48051353 0.35772831]\n",
      " [0.16692111 0.48892699 0.34415191]\n",
      " [0.17148223 0.48492038 0.34359739]\n",
      " [0.163888   0.46526328 0.37084872]\n",
      " [0.16484944 0.48534988 0.34980069]\n",
      " [0.2702264  0.43600455 0.29376905]\n",
      " [0.16672134 0.48583868 0.34743998]\n",
      " [0.16105867 0.48790919 0.35103215]\n",
      " [0.16799323 0.48242858 0.34957819]\n",
      " [0.16346069 0.47905555 0.35748377]\n",
      " [0.17869532 0.48048068 0.340824  ]\n",
      " [0.16768661 0.47588137 0.35643202]\n",
      " [0.16630689 0.48355721 0.3501359 ]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16672866 0.48004367 0.35322767]\n",
      " [0.16584123 0.49164063 0.34251814]\n",
      " [0.17697386 0.47350628 0.34951986]\n",
      " [0.1650845  0.48780626 0.34710925]\n",
      " [0.16444542 0.48668064 0.34887394]\n",
      " [0.21984742 0.47549441 0.30465817]\n",
      " [0.16344006 0.48542966 0.35113028]\n",
      " [0.16666771 0.4863156  0.34701669]\n",
      " [0.17004312 0.47226021 0.35769667]\n",
      " [0.17326711 0.47097906 0.35575383]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.1689638  0.4805474  0.3504888 ]\n",
      " [0.19480041 0.46034687 0.34485272]\n",
      " [0.17620847 0.47882051 0.34497102]\n",
      " [0.16318969 0.49537196 0.34143834]\n",
      " [0.17032072 0.4867417  0.34293758]\n",
      " [0.16629121 0.46874578 0.36496301]\n",
      " [0.16409834 0.48223345 0.3536682 ]\n",
      " [0.20269048 0.45922131 0.33808821]\n",
      " [0.16281787 0.47595637 0.36122576]\n",
      " [0.16233956 0.48061702 0.35704343]\n",
      " [0.16534906 0.48410442 0.35054652]\n",
      " [0.16474053 0.48908485 0.34617462]\n",
      " [0.18872833 0.47899719 0.33227448]\n",
      " [0.19409385 0.47474789 0.33115826]\n",
      " [0.16918722 0.48193858 0.3488742 ]\n",
      " [0.16954823 0.4755705  0.35488127]\n",
      " [0.16984901 0.49822602 0.33192497]\n",
      " [0.26488099 0.44793238 0.28718663]\n",
      " [0.16554925 0.48056044 0.35389031]\n",
      " [0.16691716 0.48620075 0.34688209]\n",
      " [0.17672129 0.48662281 0.33665589]\n",
      " [0.16777069 0.47951335 0.35271597]\n",
      " [0.17218315 0.48229669 0.34552017]\n",
      " [0.16835356 0.4726659  0.35898054]\n",
      " [0.18514843 0.46923604 0.34561553]\n",
      " [0.16905632 0.48541838 0.3455253 ]\n",
      " [0.17086582 0.48088167 0.34825251]\n",
      " [0.17265253 0.48457132 0.34277615]\n",
      " [0.16516827 0.4878041  0.34702762]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.1689163  0.49119469 0.339889  ]\n",
      " [0.1591105  0.50964292 0.33124658]\n",
      " [0.17057417 0.48362684 0.34579899]\n",
      " [0.18122763 0.47751507 0.3412573 ]\n",
      " [0.27583257 0.4391593  0.28500813]\n",
      " [0.16475069 0.48295354 0.35229577]\n",
      " [0.21984742 0.47549441 0.30465817]\n",
      " [0.16060913 0.47894257 0.3604483 ]\n",
      " [0.15527652 0.483099   0.36162448]\n",
      " [0.23925014 0.45394246 0.30680739]\n",
      " [0.16511562 0.48321718 0.3516672 ]\n",
      " [0.16891175 0.48019068 0.35089757]\n",
      " [0.16500757 0.48171967 0.35327276]\n",
      " [0.16887785 0.48088556 0.35023659]\n",
      " [0.16783992 0.48203261 0.35012747]\n",
      " [0.16349474 0.49120922 0.34529604]\n",
      " [0.16475069 0.48295354 0.35229577]\n",
      " [0.16262022 0.49634157 0.3410382 ]\n",
      " [0.16571279 0.49170843 0.34257879]\n",
      " [0.16652679 0.481836   0.35163721]\n",
      " [0.16351433 0.48736768 0.349118  ]\n",
      " [0.1688502  0.48410328 0.34704652]\n",
      " [0.16424502 0.48003211 0.35572287]\n",
      " [0.16854896 0.4877275  0.34372353]\n",
      " [0.18033148 0.47917893 0.34048959]\n",
      " [0.16955092 0.4755867  0.35486239]\n",
      " [0.16500974 0.48241713 0.35257312]\n",
      " [0.17120018 0.46614279 0.36265703]\n",
      " [0.16725692 0.48543743 0.34730565]\n",
      " [0.163888   0.46526328 0.37084872]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16822428 0.48436517 0.34741055]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.17166148 0.47226179 0.35607672]\n",
      " [0.16372611 0.48092083 0.35535306]\n",
      " [0.16055687 0.47601074 0.36343239]\n",
      " [0.16912694 0.47263995 0.35823311]\n",
      " [0.16475069 0.48295354 0.35229577]\n",
      " [0.1771408  0.48194668 0.34091251]\n",
      " [0.15964924 0.4835934  0.35675736]\n",
      " [0.1619618  0.47510658 0.36293162]\n",
      " [0.16401648 0.4914828  0.34450072]\n",
      " [0.19098581 0.48494142 0.32407277]\n",
      " [0.16622124 0.48276252 0.35101623]\n",
      " [0.1688599  0.48193707 0.34920302]\n",
      " [0.16096161 0.48061097 0.35842742]\n",
      " [0.16761781 0.49194791 0.34043428]\n",
      " [0.16485483 0.48402172 0.35112346]\n",
      " [0.20795794 0.4573509  0.33469116]\n",
      " [0.16424502 0.48003211 0.35572287]\n",
      " [0.17288179 0.48416347 0.34295474]\n",
      " [0.16725567 0.47863459 0.35410973]\n",
      " [0.17110882 0.48422054 0.34467064]\n",
      " [0.16514674 0.48393927 0.350914  ]\n",
      " [0.18226259 0.47709691 0.3406405 ]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.1695699  0.48405905 0.34637105]\n",
      " [0.18765989 0.48044114 0.33189897]\n",
      " [0.16278181 0.48149923 0.35571896]\n",
      " [0.16803727 0.48563827 0.34632446]\n",
      " [0.16841606 0.48679253 0.34479142]\n",
      " [0.1634588  0.49329806 0.34324314]\n",
      " [0.16021135 0.47184204 0.36794661]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.1695764  0.48706288 0.34336072]\n",
      " [0.16286296 0.47956186 0.35757517]\n",
      " [0.17002708 0.48054622 0.3494267 ]\n",
      " [0.19754452 0.46539594 0.33705953]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.15807876 0.47764388 0.36427736]\n",
      " [0.16500757 0.48171967 0.35327276]\n",
      " [0.16784471 0.48567496 0.34648033]\n",
      " [0.14803532 0.43062525 0.42133943]\n",
      " [0.17184833 0.47798177 0.3501699 ]\n",
      " [0.17047928 0.48700792 0.3425128 ]\n",
      " [0.16988881 0.4854138  0.34469739]\n",
      " [0.16363261 0.48191608 0.35445131]\n",
      " [0.16509886 0.48469534 0.35020581]\n",
      " [0.17173526 0.48264629 0.34561845]\n",
      " [0.170528   0.48364387 0.34582813]\n",
      " [0.15507081 0.52462306 0.32030613]\n",
      " [0.16149749 0.47915343 0.35934908]\n",
      " [0.16936337 0.4783377  0.35229893]\n",
      " [0.1700872  0.48363197 0.34628083]\n",
      " [0.16423394 0.48160769 0.35415837]\n",
      " [0.16266951 0.48325617 0.35407432]\n",
      " [0.16603359 0.48064262 0.35332379]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.18086498 0.4812511  0.33788392]\n",
      " [0.16615259 0.48591396 0.34793345]\n",
      " [0.17062069 0.46945793 0.35992138]\n",
      " [0.16891057 0.4783035  0.35278594]\n",
      " [0.17103389 0.47750744 0.35145867]\n",
      " [0.30744855 0.41951462 0.27303683]\n",
      " [0.17818333 0.48753384 0.33428283]\n",
      " [0.16535716 0.48391733 0.35072551]\n",
      " [0.17445511 0.48683693 0.33870796]\n",
      " [0.17504964 0.49206105 0.33288931]\n",
      " [0.16691021 0.48790786 0.34518193]\n",
      " [0.26952187 0.44097814 0.28949999]\n",
      " [0.21941504 0.47819656 0.3023884 ]\n",
      " [0.16576831 0.48630032 0.34793137]\n",
      " [0.16499295 0.48186671 0.35314034]\n",
      " [0.16650369 0.47825824 0.35523806]\n",
      " [0.16269961 0.48514775 0.35215264]\n",
      " [0.16496573 0.49342438 0.34160988]\n",
      " [0.18319195 0.47387386 0.34293419]\n",
      " [0.18458347 0.48410181 0.33131472]\n",
      " [0.17166383 0.48680919 0.34152698]\n",
      " [0.16708991 0.47123521 0.36167488]\n",
      " [0.16707217 0.4869532  0.34597463]\n",
      " [0.16432416 0.48602214 0.3496537 ]\n",
      " [0.16620553 0.49033915 0.34345532]\n",
      " [0.16250158 0.48176651 0.35573191]\n",
      " [0.16615259 0.48591396 0.34793345]\n",
      " [0.16615259 0.48591396 0.34793345]\n",
      " [0.16632651 0.48788803 0.34578547]\n",
      " [0.16095975 0.47823629 0.36080397]\n",
      " [0.17173956 0.4825087  0.34575175]\n",
      " [0.23533257 0.46315826 0.30150916]\n",
      " [0.16171613 0.47854135 0.35974252]\n",
      " [0.18583145 0.46510093 0.34906762]\n",
      " [0.16285478 0.47743635 0.35970887]\n",
      " [0.18704265 0.47495378 0.33800357]\n",
      " [0.21151403 0.47312712 0.31535884]\n",
      " [0.16431405 0.49009148 0.34559447]\n",
      " [0.16603719 0.48028692 0.35367589]\n",
      " [0.17010858 0.48047567 0.34941575]\n",
      " [0.1624021  0.48875071 0.34884719]\n",
      " [0.17068598 0.48376328 0.34555073]\n",
      " [0.1650845  0.48780626 0.34710925]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.18521879 0.47869371 0.3360875 ]\n",
      " [0.163888   0.46526328 0.37084872]\n",
      " [0.16163129 0.49108677 0.34728194]\n",
      " [0.16568225 0.48743329 0.34688446]\n",
      " [0.17267063 0.47196124 0.35536813]\n",
      " [0.21091337 0.45373171 0.33535492]\n",
      " [0.16491401 0.48387758 0.35120841]\n",
      " [0.18174565 0.47729001 0.34096434]\n",
      " [0.16599324 0.48803397 0.34597279]\n",
      " [0.15679872 0.4679184  0.37528288]\n",
      " [0.22664449 0.45788549 0.31547002]\n",
      " [0.16542596 0.4856324  0.34894164]\n",
      " [0.17299326 0.48279953 0.34420721]\n",
      " [0.16919109 0.48100246 0.34980645]\n",
      " [0.16318748 0.48258989 0.35422263]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.18160214 0.47783637 0.34056149]\n",
      " [0.15926354 0.47736907 0.36336739]\n",
      " [0.17184488 0.48358884 0.34456628]\n",
      " [0.1693583  0.48410019 0.34654151]\n",
      " [0.16305726 0.47895753 0.35798521]\n",
      " [0.17610152 0.48087605 0.34302244]\n",
      " [0.1656323  0.48612359 0.34824411]\n",
      " [0.1650845  0.48780626 0.34710925]\n",
      " [0.16955092 0.4755867  0.35486239]\n",
      " [0.17137885 0.49552928 0.33309187]\n",
      " [0.17357576 0.48055337 0.34587087]\n",
      " [0.16749846 0.48420647 0.34829508]\n",
      " [0.1603404  0.47722108 0.36243852]\n",
      " [0.16458452 0.48433731 0.35107817]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.1688502  0.48410328 0.34704652]\n",
      " [0.16617002 0.48431692 0.34951306]\n",
      " [0.16900018 0.4796487  0.35135111]\n",
      " [0.16795744 0.4816239  0.35041866]\n",
      " [0.16219959 0.47594831 0.3618521 ]\n",
      " [0.17288048 0.48360303 0.34351648]\n",
      " [0.18844425 0.47520759 0.33634815]\n",
      " [0.17625637 0.48587451 0.33786912]\n",
      " [0.17523488 0.48133887 0.34342625]\n",
      " [0.16452804 0.48503957 0.3504324 ]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16792453 0.47677343 0.35530204]\n",
      " [0.16951127 0.48666062 0.34382811]\n",
      " [0.1650452  0.48235069 0.35260411]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16623805 0.48475528 0.34900668]\n",
      " [0.16324069 0.48726535 0.34949396]\n",
      " [0.20187145 0.46949506 0.32863348]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.17144636 0.48036539 0.34818825]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.16441657 0.4864035  0.34917993]\n",
      " [0.16913799 0.48169275 0.34916927]\n",
      " [0.17380989 0.48800674 0.33818338]\n",
      " [0.16781428 0.4975115  0.33467422]\n",
      " [0.1814182  0.4928349  0.3257469 ]\n",
      " [0.17418413 0.48005232 0.34576355]\n",
      " [0.1640087  0.49167334 0.34431796]\n",
      " [0.16854942 0.48179763 0.34965295]\n",
      " [0.17187804 0.48427972 0.34384224]\n",
      " [0.16881219 0.48400073 0.34718709]\n",
      " [0.16717946 0.49576979 0.33705075]\n",
      " [0.1763178  0.48460206 0.33908014]\n",
      " [0.16232274 0.47695278 0.36072448]\n",
      " [0.16546054 0.48274048 0.35179899]\n",
      " [0.165802   0.48056662 0.35363138]\n",
      " [0.16097464 0.49108585 0.34793951]\n",
      " [0.16483051 0.48028648 0.35488301]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.17261943 0.48394641 0.34343416]\n",
      " [0.16468938 0.48738109 0.34792954]\n",
      " [0.17116487 0.47969632 0.34913881]\n",
      " [0.16452804 0.48503957 0.3504324 ]\n",
      " [0.16401129 0.48369372 0.352295  ]\n",
      " [0.15510197 0.4566336  0.38826443]\n",
      " [0.18533525 0.47318012 0.34148464]\n",
      " [0.16822428 0.48436517 0.34741055]\n",
      " [0.16887978 0.48522507 0.34589514]\n",
      " [0.16537406 0.4821056  0.35252034]\n",
      " [0.16324506 0.4801997  0.35655524]\n",
      " [0.16078151 0.48252752 0.35669097]\n",
      " [0.17040232 0.48486811 0.34472958]\n",
      " [0.16248494 0.49153171 0.34598335]\n",
      " [0.16323455 0.4772953  0.35947015]\n",
      " [0.18868878 0.47972822 0.331583  ]\n",
      " [0.16587978 0.48493638 0.34918384]\n",
      " [0.18104592 0.47575056 0.34320352]\n",
      " [0.17843535 0.4871954  0.33436925]\n",
      " [0.16743668 0.48010965 0.35245367]\n",
      " [0.16615259 0.48591396 0.34793345]\n",
      " [0.18241772 0.47669994 0.34088234]\n",
      " [0.16708991 0.47123521 0.36167488]\n",
      " [0.16913799 0.48169275 0.34916927]\n",
      " [0.15979293 0.47934131 0.36086577]\n",
      " [0.16464288 0.48398676 0.35137036]\n",
      " [0.1874614  0.47641872 0.33611988]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['000', '003', '01', ..., 'қазақстан', 'қалындық', 'үкімет'],\n",
       "      dtype='<U80')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ext_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "ext_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(ExtraTreesClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred3 = grid_search_cv.predict(X_test)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred3))\n",
    "print(ext_clf.feature_importances_)\n",
    "print(ext_clf.predict_proba(X_test))\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['ExtraTreesClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Два класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = {'negative': -1, 'neutral': 1, 'positive': 1} \n",
    "data['y'] = data['sentiment'].map(lambda x: y[x])\n",
    "\n",
    "data_Y = data['y'].values\n",
    "data_X = data['text'].values\n",
    "\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = train_test_split(data_Y, data_X, test_size=0.3)\n",
    "dataY_train, dataY_test, dataX_train, dataX_test = dataY_train[:700], dataY_test[:300], dataX_train[:700], dataX_test[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.14430561 0.85569439]\n",
      " [0.15261464 0.84738536]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14999497 0.85000503]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14637446 0.85362554]\n",
      " [0.14625963 0.85374037]\n",
      " [0.16189603 0.83810397]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15022067 0.84977933]\n",
      " [0.17568061 0.82431939]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15966858 0.84033142]\n",
      " [0.17436406 0.82563594]\n",
      " [0.15302318 0.84697682]\n",
      " [0.15711546 0.84288454]\n",
      " [0.15868836 0.84131164]\n",
      " [0.16006585 0.83993415]\n",
      " [0.15139726 0.84860274]\n",
      " [0.16792974 0.83207026]\n",
      " [0.15555647 0.84444353]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15300503 0.84699497]\n",
      " [0.18388506 0.81611494]\n",
      " [0.14715278 0.85284722]\n",
      " [0.14717263 0.85282737]\n",
      " [0.15030426 0.84969574]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14717263 0.85282737]\n",
      " [0.15157992 0.84842008]\n",
      " [0.15022067 0.84977933]\n",
      " [0.14430561 0.85569439]\n",
      " [0.1735438  0.8264562 ]\n",
      " [0.14657027 0.85342973]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15001981 0.84998019]\n",
      " [0.14657027 0.85342973]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14826963 0.85173037]\n",
      " [0.14657027 0.85342973]\n",
      " [0.16432883 0.83567117]\n",
      " [0.14717263 0.85282737]\n",
      " [0.1754179  0.8245821 ]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14286874 0.85713126]\n",
      " [0.14899318 0.85100682]\n",
      " [0.15897541 0.84102459]\n",
      " [0.15286052 0.84713948]\n",
      " [0.15286468 0.84713532]\n",
      " [0.17172975 0.82827025]\n",
      " [0.15894911 0.84105089]\n",
      " [0.15163955 0.84836045]\n",
      " [0.17589176 0.82410824]\n",
      " [0.15143645 0.84856355]\n",
      " [0.16547836 0.83452164]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15045582 0.84954418]\n",
      " [0.16043175 0.83956825]\n",
      " [0.16452283 0.83547717]\n",
      " [0.18466992 0.81533008]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15241421 0.84758579]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14826963 0.85173037]\n",
      " [0.14657027 0.85342973]\n",
      " [0.14657027 0.85342973]\n",
      " [0.14847352 0.85152648]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15278387 0.84721613]\n",
      " [0.14575628 0.85424372]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15479818 0.84520182]\n",
      " [0.18044363 0.81955637]\n",
      " [0.14430561 0.85569439]\n",
      " [0.1735438  0.8264562 ]\n",
      " [0.15499056 0.84500944]\n",
      " [0.14430561 0.85569439]\n",
      " [0.17667561 0.82332439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.16137187 0.83862813]\n",
      " [0.15484564 0.84515436]\n",
      " [0.14625963 0.85374037]\n",
      " [0.15891759 0.84108241]\n",
      " [0.15104213 0.84895787]\n",
      " [0.1513207  0.8486793 ]\n",
      " [0.15128052 0.84871948]\n",
      " [0.15104213 0.84895787]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15261464 0.84738536]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14657027 0.85342973]\n",
      " [0.15573779 0.84426221]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15285212 0.84714788]\n",
      " [0.15868836 0.84131164]\n",
      " [0.14847352 0.85152648]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15307905 0.84692095]\n",
      " [0.15830401 0.84169599]\n",
      " [0.15107372 0.84892628]\n",
      " [0.14715278 0.85284722]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15279045 0.84720955]\n",
      " [0.14715278 0.85284722]\n",
      " [0.15486357 0.84513643]\n",
      " [0.15116835 0.84883165]\n",
      " [0.15866266 0.84133734]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15896627 0.84103373]\n",
      " [0.15291026 0.84708974]\n",
      " [0.14430561 0.85569439]\n",
      " [0.19922836 0.80077164]\n",
      " [0.15312234 0.84687766]\n",
      " [0.14430561 0.85569439]\n",
      " [0.16624091 0.83375909]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15811032 0.84188968]\n",
      " [0.15874568 0.84125432]\n",
      " [0.15802887 0.84197113]\n",
      " [0.14657027 0.85342973]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15271668 0.84728332]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14780931 0.85219069]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15495924 0.84504076]\n",
      " [0.14430561 0.85569439]\n",
      " [0.16023265 0.83976735]\n",
      " [0.15852054 0.84147946]\n",
      " [0.16786602 0.83213398]\n",
      " [0.14715278 0.85284722]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15166535 0.84833465]\n",
      " [0.14826963 0.85173037]\n",
      " [0.15288942 0.84711058]\n",
      " [0.15862235 0.84137765]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14505013 0.85494987]\n",
      " [0.16281582 0.83718418]\n",
      " [0.14826963 0.85173037]\n",
      " [0.1515482  0.8484518 ]\n",
      " [0.15829722 0.84170278]\n",
      " [0.15500615 0.84499385]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15259546 0.84740454]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15041629 0.84958371]\n",
      " [0.14430561 0.85569439]\n",
      " [0.1513207  0.8486793 ]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15423454 0.84576546]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14657027 0.85342973]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.16768986 0.83231014]\n",
      " [0.17230386 0.82769614]\n",
      " [0.15958866 0.84041134]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15912051 0.84087949]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14293796 0.85706204]\n",
      " [0.16831382 0.83168618]\n",
      " [0.15462051 0.84537949]\n",
      " [0.14430561 0.85569439]\n",
      " [0.1574939  0.8425061 ]\n",
      " [0.14899318 0.85100682]\n",
      " [0.15951033 0.84048967]\n",
      " [0.1635112  0.8364888 ]\n",
      " [0.14430561 0.85569439]\n",
      " [0.16630437 0.83369563]\n",
      " [0.15958955 0.84041045]\n",
      " [0.15081285 0.84918715]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15001362 0.84998638]\n",
      " [0.15744623 0.84255377]\n",
      " [0.1528729  0.8471271 ]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15305019 0.84694981]\n",
      " [0.15280633 0.84719367]\n",
      " [0.17586594 0.82413406]\n",
      " [0.15261464 0.84738536]\n",
      " [0.16725166 0.83274834]\n",
      " [0.15646343 0.84353657]\n",
      " [0.14430561 0.85569439]\n",
      " [0.17457464 0.82542536]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15261902 0.84738098]\n",
      " [0.15009751 0.84990249]\n",
      " [0.1599043  0.8400957 ]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14657027 0.85342973]\n",
      " [0.17088657 0.82911343]\n",
      " [0.15868836 0.84131164]\n",
      " [0.15589856 0.84410144]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15939456 0.84060544]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14575628 0.85424372]\n",
      " [0.16367245 0.83632755]\n",
      " [0.14625963 0.85374037]\n",
      " [0.15022365 0.84977635]\n",
      " [0.16291313 0.83708687]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14625963 0.85374037]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.16483018 0.83516982]\n",
      " [0.17107514 0.82892486]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.16242652 0.83757348]\n",
      " [0.15289161 0.84710839]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14657027 0.85342973]\n",
      " [0.15009751 0.84990249]\n",
      " [0.15042755 0.84957245]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15813443 0.84186557]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15305019 0.84694981]\n",
      " [0.17136287 0.82863713]\n",
      " [0.1542279  0.8457721 ]\n",
      " [0.16626773 0.83373227]\n",
      " [0.17500552 0.82499448]\n",
      " [0.1688005  0.8311995 ]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15091153 0.84908847]\n",
      " [0.16109913 0.83890087]\n",
      " [0.18906504 0.81093496]\n",
      " [0.15091507 0.84908493]\n",
      " [0.15280633 0.84719367]\n",
      " [0.14430561 0.85569439]\n",
      " [0.1614788  0.8385212 ]\n",
      " [0.15009751 0.84990249]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15022067 0.84977933]\n",
      " [0.16004221 0.83995779]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15285399 0.84714601]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14715278 0.85284722]\n",
      " [0.14826963 0.85173037]\n",
      " [0.1619279  0.8380721 ]\n",
      " [0.14715278 0.85284722]\n",
      " [0.16817233 0.83182767]\n",
      " [0.1480445  0.8519555 ]\n",
      " [0.15283933 0.84716067]\n",
      " [0.16019508 0.83980492]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15505512 0.84494488]\n",
      " [0.15582422 0.84417578]\n",
      " [0.14625963 0.85374037]\n",
      " [0.15302318 0.84697682]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15097133 0.84902867]\n",
      " [0.15654523 0.84345477]\n",
      " [0.14625963 0.85374037]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14860609 0.85139391]\n",
      " [0.15513237 0.84486763]\n",
      " [0.15890114 0.84109886]\n",
      " [0.15280271 0.84719729]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14430561 0.85569439]\n",
      " [0.14625963 0.85374037]\n",
      " [0.14715278 0.85284722]\n",
      " [0.14282135 0.85717865]\n",
      " [0.15838806 0.84161194]\n",
      " [0.17070362 0.82929638]\n",
      " [0.15633435 0.84366565]\n",
      " [0.1480445  0.8519555 ]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15271668 0.84728332]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15958955 0.84041045]\n",
      " [0.14430561 0.85569439]\n",
      " [0.15391396 0.84608604]\n",
      " [0.14899318 0.85100682]\n",
      " [0.16630231 0.83369769]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1b401d3d163a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnd_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnd_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mour_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CountVectorizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mour_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RandomForestClassifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "rnd_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred2 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred2)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred2))\n",
    "print(rnd_clf.feature_importances_)\n",
    "print(rnd_clf.predict_proba(X_test))\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred2))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['RandomForestClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7766666666666666\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.15091678 0.84908322]\n",
      " [0.15609285 0.84390715]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15943048 0.84056952]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15445905 0.84554095]\n",
      " [0.15091678 0.84908322]\n",
      " [0.17641102 0.82358898]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14950982 0.85049018]\n",
      " [0.15091678 0.84908322]\n",
      " [0.17308693 0.82691307]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15608852 0.84391148]\n",
      " [0.16508507 0.83491493]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15940381 0.84059619]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15541389 0.84458611]\n",
      " [0.15177659 0.84822341]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15608272 0.84391728]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15958203 0.84041797]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15445905 0.84554095]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16293126 0.83706874]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15609715 0.84390285]\n",
      " [0.16296773 0.83703227]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15294185 0.84705815]\n",
      " [0.15338078 0.84661922]\n",
      " [0.15940381 0.84059619]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15940815 0.84059185]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.17034258 0.82965742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15809772 0.84190228]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15338078 0.84661922]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15941171 0.84058829]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15945905 0.84054095]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15356599 0.84643401]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.18785116 0.81214884]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15958203 0.84041797]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15659586 0.84340414]\n",
      " [0.1645381  0.8354619 ]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16453965 0.83546035]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15691822 0.84308178]\n",
      " [0.15945905 0.84054095]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.1554299  0.8445701 ]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14950982 0.85049018]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15608852 0.84391148]\n",
      " [0.1531799  0.8468201 ]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15941822 0.84058178]\n",
      " [0.15691389 0.84308611]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15691389 0.84308611]\n",
      " [0.15356599 0.84643401]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16289308 0.83710692]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15608852 0.84391148]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15541389 0.84458611]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15541389 0.84458611]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15992917 0.84007083]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15442186 0.84557814]\n",
      " [0.1665891  0.8334109 ]\n",
      " [0.1623455  0.8376545 ]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16789519 0.83210481]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15939379 0.84060621]\n",
      " [0.15356599 0.84643401]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15338078 0.84661922]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.1867357  0.8132643 ]\n",
      " [0.15939597 0.84060403]\n",
      " [0.15941605 0.84058395]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15959209 0.84040791]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15939597 0.84060403]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.18860814 0.81139186]\n",
      " [0.15356599 0.84643401]\n",
      " [0.1538663  0.8461337 ]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15440598 0.84559402]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15441171 0.84558829]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16788518 0.83211482]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15441389 0.84558611]\n",
      " [0.15294185 0.84705815]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16976387 0.83023613]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15280179 0.84719821]\n",
      " [0.15445905 0.84554095]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14940953 0.85059047]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.14950982 0.85049018]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.20447338 0.79552662]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15338078 0.84661922]\n",
      " [0.15607265 0.84392735]\n",
      " [0.16407484 0.83592516]\n",
      " [0.15607047 0.84392953]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15338078 0.84661922]\n",
      " [0.15091678 0.84908322]\n",
      " [0.17139026 0.82860974]\n",
      " [0.15607047 0.84392953]\n",
      " [0.15091678 0.84908322]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16457625 0.83542375]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15808553 0.84191447]\n",
      " [0.15788586 0.84211414]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16987268 0.83012732]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16207409 0.83792591]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15280751 0.84719249]\n",
      " [0.14940953 0.85059047]\n",
      " [0.15439379 0.84560621]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.17642745 0.82357255]\n",
      " [0.15338078 0.84661922]\n",
      " [0.15541605 0.84458395]\n",
      " [0.16540092 0.83459908]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15691389 0.84308611]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16857194 0.83142806]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15941389 0.84058611]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15514047 0.84485953]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.1645799  0.8354201 ]\n",
      " [0.15091678 0.84908322]\n",
      " [0.17631336 0.82368664]\n",
      " [0.15991897 0.84008103]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16791972 0.83208028]\n",
      " [0.14789519 0.85210481]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16133236 0.83866764]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15445905 0.84554095]\n",
      " [0.14931258 0.85068742]\n",
      " [0.15855686 0.84144314]\n",
      " [0.1531799  0.8468201 ]\n",
      " [0.17554316 0.82445684]\n",
      " [0.1519618  0.8480382 ]\n",
      " [0.15992917 0.84007083]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.16186999 0.83813001]\n",
      " [0.15530969 0.84469031]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15440598 0.84559402]\n",
      " [0.15542186 0.84457814]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]\n",
      " [0.15091678 0.84908322]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ce4b7907e737>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mour_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CountVectorizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mour_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ExtraTreesClassifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ext_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=100, max_depth=2, random_state=0)\n",
    "ext_clf.fit(X_train, dataY_train)\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier())]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'max_depth': list(range(3, 8)), 'n_estimators': list(range(3, 8))}\n",
    "grid_search_cv = GridSearchCV(ExtraTreesClassifier(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred3 = grid_search_cv.predict(X_test)\n",
    "accuracy_score(dataY_test, y_pred3)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred3))\n",
    "print(ext_clf.feature_importances_)\n",
    "print(ext_clf.predict_proba(X_test))\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred3))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['ExtraTreesClassifier'].feature_importances_ != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        66\n",
      "          1       0.78      1.00      0.88       234\n",
      "\n",
      "avg / total       0.61      0.78      0.68       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['01', '1332', '2015', '2017', '21', '26', '60', '90', 'com',\n",
       "       'kase', 'kz', 'today', 'vedomosti', 'автомобиль', 'агентства',\n",
       "       'акишев', 'акции', 'акционеров', 'алматы', 'анна', 'ао', 'аппарат',\n",
       "       'астана', 'атырау', 'байтерек', 'банк', 'банка', 'безопасности',\n",
       "       'билеты', 'бишимбаев', 'более', 'будут', 'бывшего', 'был', 'была',\n",
       "       'были', 'было', 'вагонов', 'ведомства', 'вернуться', 'вице', 'во',\n",
       "       'возможность', 'вот', 'время', 'все', 'всего', 'выручка', 'главы',\n",
       "       'говорит', 'года', 'году', 'города', 'граждан', 'данные',\n",
       "       'декабря', 'дел', 'детей', 'деятельности', 'директоров', 'для',\n",
       "       'должен', 'дом', 'другие', 'других', 'единиц', 'ему', 'енпф',\n",
       "       'ерденаева', 'же', 'за', 'завода', 'заседания', 'заявление',\n",
       "       'здравоохранения', 'или', 'имеет', 'иране', 'источник', 'итогам',\n",
       "       'казахстан', 'казахстана', 'казахстане', 'казахстанских',\n",
       "       'казахстанской', 'казинвестбанка', 'ккм', 'кодекса', 'конструкции',\n",
       "       'которые', 'который', 'которым', 'кск', 'ктж', 'лет',\n",
       "       'ликвидности', 'между', 'меньше', 'месяца', 'миллиардов',\n",
       "       'министра', 'млрд', 'многомиллиардных', 'мнэ', 'может', 'момент',\n",
       "       'мы', 'на', 'нажмите', 'нам', 'нацбанк', 'национальной', 'ндс',\n",
       "       'не', 'оао', 'объем', 'однако', 'отметил', 'отмечается',\n",
       "       'отношении', 'парка', 'пенсионные', 'пенсионных', 'первого', 'по',\n",
       "       'полицейские', 'полиции', 'порту', 'пош', 'правительства',\n",
       "       'правительство', 'предпринимателей', 'председателем', 'президент',\n",
       "       'пресс', 'признались', 'прогнозирует', 'проекта', 'произошел',\n",
       "       'произошла', 'процента', 'развития', 'размере', 'расследование',\n",
       "       'ребенка', 'результате', 'рельсов', 'самрук', 'саранская', 'своих',\n",
       "       'связи', 'себя', 'сказал', 'скорой', 'словам', 'сообщает',\n",
       "       'сообщению', 'составляет', 'специальная', 'средств', 'средства',\n",
       "       'стал', 'стран', 'страны', 'строительство', 'суда', 'так', 'тенге',\n",
       "       'тенге1', 'то', 'того', 'том', 'тоо', 'трлн', 'трудового', 'тысяч',\n",
       "       'тэц', 'тяжелой', 'убытках', 'уголовного', 'ук', 'уровень',\n",
       "       'участие', 'февраля', 'фонд', 'центр', 'чем', 'что', 'чтобы',\n",
       "       'шахте', 'шаяхметова', 'экономики', 'энерго', 'это', 'январь'],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "our_pipeline = Pipeline( [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('LogisticRegression', LogisticRegression(penalty='l1'))]\n",
    ")\n",
    "\n",
    "our_pipeline.fit(dataX_train, dataY_train)\n",
    "\n",
    "param_grid = {'C': list(range(1, 5)), 'penalty': ['l1', 'l2']}\n",
    "grid_search_cv = GridSearchCV(LogisticRegression(), param_grid, cv = 3)\n",
    "grid_search_cv.fit(X_train, dataY_train)\n",
    "\n",
    "y_pred4 = grid_search_cv.predict(X_test)\n",
    "\n",
    "print(accuracy_score(dataY_test, y_pred4))\n",
    "\n",
    "print(classification_report(y_true=dataY_test, y_pred=y_pred4))\n",
    "\n",
    "np.array(our_pipeline.named_steps['CountVectorizer'].get_feature_names())[np.where(our_pipeline.named_steps['LogisticRegression'].coef_ != 0)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
